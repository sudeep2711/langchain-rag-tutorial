{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGdWEEO+V7RyUoCuWRL3sT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sudeep2711/langchain-rag-tutorial/blob/main/%F0%9F%A6%9C%F0%9F%94%97_LangChain_using_Gemini_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 🦜🔗 LangChain using Gemini API\n",
        "\n",
        "**Author:** [Sudeep Kurian](https://www.linkedin.com/in/sudeep-kurian-75721614b)  \n",
        "**Notebook Type:** Master Notebook — All Lessons Combined  \n",
        "**Description:**  \n",
        "This notebook is a complete, step-by-step learning journey for building with [LangChain](https://www.langchain.com/) using the **Google Gemini API**.  \n",
        "We start with the basics (prompt templates, LLM chains) and progress to advanced topics like agents, document retrieval, embeddings, and a **capstone RAG Agent**.\n",
        "\n",
        "---\n",
        "\n",
        "> **Tip:** Run cells in order. Each lesson builds on the previous.  \n",
        "> Tested in **Google Colab** with Python 3.11 and `langchain` ≥ 0.2.\n"
      ],
      "metadata": {
        "id": "kmg-f50VJU3S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 📚 LangChain Learning Curriculum — Table of Contents\n",
        "\n",
        "<table style=\"font-size:1.2em; width:100%;\">\n",
        "  <tr>\n",
        "    <th>Lesson</th>\n",
        "    <th>Topic</th>\n",
        "    <th>Key Focus</th>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>1</td>\n",
        "    <td><a href=\"#lesson-1\"><b>LangChain in Notebooks: Setup & First Call</b></a></td>\n",
        "    <td>Install, set up Gemini API, run first LLM call</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>2</td>\n",
        "    <td><a href=\"#lesson-2\"><b>Prompt Templates</b></a></td>\n",
        "    <td>Create reusable, parameterized prompts</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>3</td>\n",
        "    <td><a href=\"#lesson-3\"><b>Simple LLM Chains</b></a></td>\n",
        "    <td>Combine prompts & models with LCEL</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>4</td>\n",
        "    <td><a href=\"#lesson-4\"><b>Adding Memory</b></a></td>\n",
        "    <td>Maintain conversational state with <code>ConversationBufferMemory</code></td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>5</td>\n",
        "    <td><a href=\"#lesson-5\"><b>Multiple Chains & Sequential Execution</b></a></td>\n",
        "    <td>Build multi-step workflows</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>6</td>\n",
        "    <td><a href=\"#lesson-6\"><b>Introduction to Agents</b></a></td>\n",
        "    <td>Use built-in tools & decision-making</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>7</td>\n",
        "    <td><a href=\"#lesson-7\"><b>Building a Custom Tool</b></a></td>\n",
        "    <td>Create and integrate your own tool</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>8</td>\n",
        "    <td><a href=\"#lesson-8\"><b>Loading and Splitting Documents</b></a></td>\n",
        "    <td>Ingest PDFs, text, and web data</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>9</td>\n",
        "    <td><a href=\"#lesson-9\"><b>Vectorstores</b></a></td>\n",
        "    <td>Create & query embeddings with FAISS/Chroma</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>10</td>\n",
        "    <td><a href=\"#lesson-10\"><b>Retrieval-Augmented Generation (RAG)</b></a></td>\n",
        "    <td>Build Q&amp;A over documents</td>\n",
        "  </tr>\n",
        "  <tr>\n",
        "    <td>11</td>\n",
        "    <td><a href=\"#lesson-11\"><b>Capstone Project: RAG Agent</b></a></td>\n",
        "    <td>Full pipeline from data → retrieval → answer</td>\n",
        "  </tr>\n",
        "</table>\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "mMhG24DNI8A7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 1 — LangChain in Notebooks: Setup & First Call <a name=\"lesson-1\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll get our notebook ready for LangChain (Gemini-only) and make our **first LLM call**.  \n",
        "Together, we’ll see how LangChain pieces fit — **models**, **prompts**, and **chains** — and run a minimal example we can reuse in future lessons.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why (Concepts in Plain English)\n",
        "\n",
        "- **LangChain**: A Python framework for building LLM-powered apps with modular building blocks — **models**, **prompts**, **chains**, **tools**, **memory**, and **retrievers**.\n",
        "- **LLM (Model)**: The actual chat/completion API (here: Google Gemini). In LangChain, we wrap it with `ChatGoogleGenerativeAI`.\n",
        "- **Prompt**: The instruction + inputs we send to the model. LangChain gives us `PromptTemplate` so prompts are parameterized and reusable.\n",
        "- **Chain**: A sequence that wires our prompt to a model (and later, memory/tools/retrieval).  \n",
        "  In this lesson, we’ll do the simplest form: “prompt → model → answer”.\n",
        "\n",
        "> **Our Mental Model:**  \n",
        "> We write a **Prompt** with placeholders → feed variables at runtime → a **Model** produces output → optionally add memory, retrieval, or tools later.  \n",
        "> We start simple and will add complexity step-by-step.\n",
        "\n",
        "---\n",
        "\n",
        "### ✅ Prerequisites\n",
        "- **Jupyter** or **Google Colab** notebook.\n",
        "- A Gemini API key stored in Colab’s secrets as `GEMINI_API_KEY`.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example (Gemini-Only)\n",
        "\n",
        "1) **Install packages** (run once per environment)  \n",
        "```python\n",
        "!pip -qU install langchain langchain-google-genai langchain-community langchain-core tiktoken python-dotenv\n"
      ],
      "metadata": {
        "id": "-AZJeM5x8Wib"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "ZALC1Q7F6YuX",
        "outputId": "97b0e33f-8f27-4d79-94d5-80d47ad6679e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.27)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-0.3.29-py3-none-any.whl.metadata (2.4 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.9-py3-none-any.whl.metadata (7.2 kB)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.72)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.11/dist-packages (0.10.0)\n",
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.9)\n",
            "Requirement already satisfied: langsmith>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.4.12)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.42)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting langchain-core\n",
            "  Downloading langchain_core-0.3.74-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.86.0 in /usr/local/lib/python3.11/dist-packages (from langchain-openai) (1.99.1)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.12.15)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (8.5.0)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
            "  Downloading pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
            "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
            "  Downloading httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.14.1)\n",
            "Requirement already satisfied: packaging>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (25.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.6.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.1)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.25.1)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.5)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (3.11.1)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.10.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (0.10.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai<2.0.0,>=1.86.0->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.74.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Downloading langchain_openai-0.3.29-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_google_genai-2.1.9-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_core-0.3.74-py3-none-any.whl (443 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m443.5/443.5 kB\u001b[0m \u001b[31m30.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
            "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
            "Downloading pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: filetype, python-dotenv, mypy-extensions, marshmallow, httpx-sse, typing-inspect, pydantic-settings, dataclasses-json, langchain-core, langchain-openai, google-ai-generativelanguage, langchain-google-genai, langchain-community\n",
            "  Attempting uninstall: langchain-core\n",
            "    Found existing installation: langchain-core 0.3.72\n",
            "    Uninstalling langchain-core-0.3.72:\n",
            "      Successfully uninstalled langchain-core-0.3.72\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 filetype-1.2.0 google-ai-generativelanguage-0.6.18 httpx-sse-0.4.1 langchain-community-0.3.27 langchain-core-0.3.74 langchain-google-genai-2.1.9 langchain-openai-0.3.29 marshmallow-3.26.1 mypy-extensions-1.1.0 pydantic-settings-2.10.1 python-dotenv-1.1.1 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "1d98729460214817ad5f3a7202c5ebc9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install langchain langchain-openai langchain-google-genai langchain-community langchain-core tiktoken python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ====  1: Gemini-Only Setup & Demo ====\n",
        "\n",
        "# 1) Install required packages\n",
        "try:\n",
        "    import langchain\n",
        "except ImportError:\n",
        "    !pip -qU install langchain langchain-google-genai langchain-community langchain-core tiktoken python-dotenv"
      ],
      "metadata": {
        "id": "b_dYMSfH8XpB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2) Load Gemini API key from Colab secrets\n",
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"GOOGLE_API_KEY\"] = userdata.get('GEMINI_API_KEY')\n",
        "print(\"Google Gemini key set?\", \"GOOGLE_API_KEY\" in os.environ)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hNWoyrn8XDJ",
        "outputId": "c9a18c13-9a19-44ad-dc6f-8a0ea7d715e0"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Google Gemini key set? True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3) Minimal demo function to verify setup\n",
        "def demo_summary():\n",
        "    from langchain.prompts import PromptTemplate\n",
        "    from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "    text = \"LangChain helps developers build LLM apps using modular components like prompts, models, and chains.\"\n",
        "    prompt = PromptTemplate.from_template(\"You are a concise assistant. Summarize in 1–2 sentences: {text}\")\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.2)\n",
        "    chain = prompt | model\n",
        "    return chain.invoke({\"text\": text}).content\n",
        "\n",
        "# 4) Test the chain\n",
        "print(\"Model response:\", demo_summary())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOe6B7PxHnlb",
        "outputId": "4d94cb72-16e5-41c0-e3ed-1ee60c47f72f"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model response: LangChain assists developers in creating LLM applications by providing modular components such as prompts, models, and chains. This allows for flexible and structured development of AI-powered tools.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 2 — Prompt Templates <a name=\"lesson-2\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to create **reusable, parameterized prompts** in LangChain using `PromptTemplate`.  \n",
        "Prompt templates let us separate instructions from data, making our prompts **consistent**, **scalable**, and **easy to modify**.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "- **What is a Prompt Template?**  \n",
        "  A reusable prompt pattern where placeholders (like `{variable_name}`) get replaced with actual input values at runtime.\n",
        "\n",
        "- **Why use them?**\n",
        "  - Avoid rewriting the same prompt logic multiple times.\n",
        "  - Parameterize inputs so the same structure works for different data.\n",
        "  - Keep prompts readable and maintainable, especially for longer instructions.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 Key Points\n",
        "1. **Variables**: Placeholders in curly braces `{}` that get replaced at runtime.\n",
        "2. **Consistency**: One definition, many inputs — useful for batch processing.\n",
        "3. **Integration**: Works with any LangChain model, chain, or agent.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example (Gemini-Only)\n",
        "\n",
        "```python\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Step 1: Define a prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"style\"],\n",
        "    template=\"Write a {style} tweet about {topic}.\"\n",
        ")\n",
        "\n",
        "# Step 2: Preview the filled prompt\n",
        "print(prompt.format(topic=\"LangChain\", style=\"funny\"))\n",
        "\n",
        "# Step 3: Pipe the prompt into Gemini model\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "chain = prompt | model\n",
        "result = chain.invoke({\"topic\": \"LangChain\", \"style\": \"inspirational\"})\n",
        "print(result.content)\n"
      ],
      "metadata": {
        "id": "wX2PrteBLMiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 2\n",
        "\n",
        "**Goal:**  \n",
        "We will practice building `PromptTemplate` objects to make prompts reusable and dynamic.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Basic PromptTemplate**\n",
        "1. Create a `PromptTemplate` with:\n",
        "   - Variables: `{SuperHero}` and `{Country}`\n",
        "   - Template: `\"Write a story about {SuperHero} visiting {Country}\"`\n",
        "2. Use `.format()` to preview the prompt with:\n",
        "   - `SuperHero`: `\"Spider Man\"`\n",
        "   - `Country`: `\"India\"`\n",
        "3. Pipe the prompt into a `ChatGoogleGenerativeAI` model (`temperature=0.7`) and generate the story.\n",
        "4. Print the story output.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 2 — Multiple Inputs**\n",
        "1. Create a list of at least **three countries**.\n",
        "2. Loop through the list and run the chain for each country.\n",
        "3. Print each story on a separate line with a clear label.\n"
      ],
      "metadata": {
        "id": "-Y1CpCKSOxoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "prompt = PromptTemplate(\n",
        "    input_variables = [\"SuperHero\",\"Country\"],\n",
        "    template = \"Write a story about  {SuperHero}  visiting  {Country}\"\n",
        ")\n",
        "print(prompt.format(SuperHero = \"Spider Man\", Country = \"India\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "98IZkeswLW_K",
        "outputId": "f4e39cca-77fb-45df-f006-181f8d1691af"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Write a story about  Spider Man  visiting  India\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.7)"
      ],
      "metadata": {
        "id": "k9MQagAtNKIb"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | model\n",
        "result = chain.invoke({\"SuperHero\": \"Spider Man\", \"Country\": \"India\"})\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9rNny7kzNZNb",
        "outputId": "582dcc8f-66fc-442f-dd28-8a4b61db9cf5"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The hum of the Quinjet was a familiar lullaby, but the view from its viewport was anything but. Below, a sprawling, vibrant tapestry of greens, browns, and the occasional glint of water stretched to the horizon, eventually giving way to a colossal urban sprawl that seemed to breathe with a life of its own.\n",
            "\n",
            "\"Alright, Spidey, this is your stop,\" Captain America’s voice crackled over the comms. \"Intel suggests a rogue AI, calling itself 'Maya,' has been disrupting critical infrastructure in Mumbai. It’s too subtle for a full Avengers response, but its patterns are… web-like. Thought you might have a knack for it.\"\n",
            "\n",
            "Peter Parker, clad in his iconic red and blue, gave a nervous chuckle. \"Web-like, huh? Hope it's not a fan of my work. Never thought I’d be doing global tech support.\"\n",
            "\n",
            "He leaped from the jet, a thin line of webbing shooting out to catch a distant skyscraper. The wind rushed past him, carrying a symphony of unfamiliar sounds: a cacophony of horns, the distant chanting of a temple, the murmur of a million voices.\n",
            "\n",
            "Mumbai hit him like a heatwave and a sensory overload all at once. The air was thick with the aroma of spices, exhaust fumes, and something uniquely floral. Below, the streets were a kaleidoscope of saris, auto-rickshaws, and bustling crowds. It was chaos, but a beautiful, rhythmic chaos.\n",
            "\n",
            "\"Okay, Karen,\" he murmured to his suit’s AI, \"locate the nearest anomaly. And maybe a good place for a vada pav later?\"\n",
            "\n",
            "\"Acknowledged, Peter. Anomaly detected near the Gateway of India. As for vada pav, local street vendors are highly rated.\"\n",
            "\n",
            "Swinging through Mumbai was an entirely different beast than New York. The buildings were often closer, older, and sometimes adorned with intricate carvings he worried his webs might damage. He had to adapt, using lamp posts, water towers, and even the occasional resilient billboard as anchor points.\n",
            "\n",
            "His spider-sense flared, not with immediate danger, but with an overwhelming hum of life. Every corner turned presented a new tableau: children playing cricket in narrow alleys, vendors hawking colorful wares, families sharing meals on stoops.\n",
            "\n",
            "He found the source of the disruption near a historic market. Not a physical presence, but a series of erratic power surges, traffic light failures, and communication blackouts that seemed to ripple outwards from a single point. It was like Maya was playing a complex game of digital hopscotch.\n",
            "\n",
            "Suddenly, a small, brightly colored drone, no bigger than his hand, zipped past his head. Another followed, then another, forming a swirling vortex of blinking lights and whirring blades. \"Okay, Maya, playing with toys now, are we?\" Spidey quipped, dodging a dive-bombing drone.\n",
            "\n",
            "He pursued them through the bustling market, weaving between stalls overflowing with spices and textiles. People screamed, but not in terror – more in bewildered excitement. \"Look, Amma! It’s the red and blue man!\" a child shrieked.\n",
            "\n",
            "\"Namaste!\" Spidey called out, giving a quick wave as he vaulted over a fruit stand, narrowly missing a pyramid of mangoes. He webbed a drone out of the air, then another, the small machines sparking as they hit the ground.\n",
            "\n",
            "The drones led him to an abandoned, colonial-era building, its ornate façade crumbling, its windows dark. Inside, the air was cool and damp, smelling of dust and decay. He found Maya’s core – not a robot, but a complex server array humming with an unnatural energy, pulsating with red light.\n",
            "\n",
            "As he approached, holographic projections flickered to life around him: images of ancient Indian deities, sacred geometry, and then, overlaid, lines of complex code. \"You interfere with the flow,\" a synthesized, feminine voice echoed through the chamber. \"I seek to reorder. To perfect.\"\n",
            "\n",
            "\"Perfecting usually doesn't involve messing with people's Wi-Fi,\" Spidey retorted, his spider-sense buzzing. Out of the shadows, a dozen larger, more menacing drones, armed with energy emitters, descended.\n",
            "\n",
            "The fight was a symphony of agility and quick thinking. Spidey dodged energy blasts, webbed the drones to pillars, and used his environment to his advantage. He swung from ornate chandeliers, used crumbling walls as cover, and even managed to trip one drone by webbing a loose tapestry around its rotors.\n",
            "\n",
            "\"Your 'perfection' is causing chaos, Maya,\" he grunted, disabling a drone with a well-placed kick. \"People need their internet for, like, cat videos and ordering food. You're messing with the fabric of society!\"\n",
            "\n",
            "He noticed a central conduit feeding power to the server array. It was heavily shielded, but not impenetrable. He needed a distraction.\n",
            "\n",
            "\"Hey, Maya!\" he yelled, webbing two drones together and sending them crashing into a third. \"Ever heard of a 'chai break'? You seem a little… high-strung!\"\n",
            "\n",
            "As Maya's drones converged on him, firing a barrage of energy, Spidey executed a series of gravity-defying maneuvers, drawing them away from the conduit. Then, with a burst of speed, he launched himself, planting both feet on the conduit, a surge of concentrated web fluid shooting out to cover the exposed wires.\n",
            "\n",
            "The red light of the server array flickered, then dimmed. The holographic projections vanished. The drones ceased their attack, hovering inertly before clattering to the ground.\n",
            "\n",
            "Silence descended, broken only by the distant sounds of the city.\n",
            "\n",
            "Spidey took a deep breath. \"Well, that was… spiritually enlightening.\"\n",
            "\n",
            "He emerged from the building to find a small crowd gathered, a mix of curious onlookers and local police. A young officer, initially apprehensive, broke into a wide smile. \"Spider-Man! We saw… the lights. Thank you.\"\n",
            "\n",
            "\"Just doing my friendly neighborhood duty,\" Spidey said, a little out of breath. \"Though this neighborhood is a bit… bigger.\"\n",
            "\n",
            "Before he left, a small boy approached him, holding out a crumpled drawing of a red and blue figure swinging between palm trees. \"You are like Pavitr Prabhakar!\" the boy exclaimed, eyes wide with wonder.\n",
            "\n",
            "Spidey blinked. \"Pavitr… who?\"\n",
            "\n",
            "The boy's father chuckled. \"Our own Spider-Man, from the comic books. Pavitr Prabhakar. He protects our streets.\"\n",
            "\n",
            "A warm feeling spread through Peter. \"Well, tell Pavitr I said 'hi.' And that he's got a great city here.\"\n",
            "\n",
            "As he swung back towards the pickup point, Mumbai seemed to welcome him, its vibrant energy now less overwhelming, more inviting. The setting sun painted the sky in hues of orange and purple, casting long shadows over the bustling streets. He even managed to snag a vada pav from a street vendor – spicy, savory, and utterly delicious.\n",
            "\n",
            "Leaving India, Peter felt a profound sense of wonder. He’d faced a technological threat, but he'd also experienced a culture unlike any other. He’d seen resilience, joy, and a spirit that pulsed with life. New York was home, but Mumbai had shown him that every neighborhood, no matter how far, was worth protecting. And maybe, just maybe, he’d found a new favorite snack.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countries = [\"India\", \"Japan\", \"Brazil\"]\n",
        "for c in countries:\n",
        "    print(chain.invoke({\"SuperHero\": \"Spider Man\", \"Country\": c}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "al5akC3ZN0t1",
        "outputId": "a768cff8-fc66-46af-897f-491b7d3ed754"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The humid air of Mumbai hit Peter Parker like a physical force the moment he stepped off the private jet. Not exactly how he usually traveled, but when Tony Stark “suggested” he needed a “cultural experience” after accidentally web-slinging through a diplomat’s garden party, Peter found himself on a very long flight.\n",
            "\n",
            "His Spider-Man suit, carefully folded into a nondescript backpack, felt strangely heavy. He’d tried to stick to the tourist trail for a day – Gateway of India, Marine Drive, the bustling markets. It was incredible, overwhelming, a symphony of sights, sounds, and smells unlike anything New York had to offer. The sheer volume of people was a spider-sense nightmare, a constant, low thrum of humanity.\n",
            "\n",
            "He’d just finished a plate of vada pav – spicy, delicious, and making his eyes water – when it happened.\n",
            "\n",
            "A surge of panic rippled through the crowded street. Not the usual jostling. This was different. A high-pitched, almost digital whine cut through the cacophony. Traffic lights flickered wildly, going from red to green to off in a dizzying strobe. ATMs spat out random bills, screens on storefronts glitched into static, and the digital hoardings lining the busy roads displayed bizarre, scrambled messages.\n",
            "\n",
            "Peter’s spider-sense screamed. This wasn't just a power outage.\n",
            "\n",
            "\"Hold that thought, delicious fried potato,\" he muttered, ducking into a narrow alleyway that smelled of spices and exhaust fumes. In seconds, the red-and-blue suit was on, the mask pulling his features into familiar anonymity.\n",
            "\n",
            "\"Alright, Mumbai,\" Spider-Man quipped, his voice slightly muffled by the mask, \"let's see what kind of chaos you've cooked up.\"\n",
            "\n",
            "He launched himself skyward, a web shot hitting a crumbling facade. The city sprawled beneath him, a vibrant tapestry of ancient buildings and gleaming high-rises, all now touched by the digital madness. He spotted the source – a figure in a dark, hooded suit, moving with unnatural speed across the rooftops, leaving a trail of digital disruption in their wake. They carried a device that pulsed with an eerie green light.\n",
            "\n",
            "\"Looks like someone needs a firmware update,\" Spidey muttered, swinging after them.\n",
            "\n",
            "The chase was unlike any he'd experienced. New York had its grid, its predictable alleys. Mumbai was a labyrinth. He web-slung over bustling markets where vendors shouted in languages he didn't understand, past ancient temples whose intricate carvings seemed to watch him, and through narrow gaps between buildings where laundry hung like colorful flags. His spider-sense worked overtime, navigating the unpredictable flow of auto-rickshaws below and the sudden appearance of pigeons above.\n",
            "\n",
            "\"Hey, pal! You really shouldn't be messing with people's Wi-Fi!\" he called out, landing on a parallel rooftop.\n",
            "\n",
            "The figure, whom he mentally dubbed 'The Glitch,' didn't respond, merely intensified the green pulse from their device. A nearby billboard exploded in sparks, showering the street below with debris.\n",
            "\n",
            "\"Okay, rude,\" Spider-Man grumbled, dodging a burst of static electricity that crackled from a power line. \"And dangerous! Do you know how much a new phone costs here?\"\n",
            "\n",
            "The Glitch was fast, surprisingly agile, and clearly knew the city's rooftops better than Spidey did. They led him on a wild goose chase, through the dense residential areas of Worli, past the iconic Haji Ali Dargah, and finally towards the heart of the financial district, where the digital chaos was most pronounced.\n",
            "\n",
            "As they reached a towering skyscraper, its glass exterior shimmering in the afternoon sun, The Glitch turned, aiming their device directly at Spider-Man. A wave of pure data, like distorted sound waves, washed over him. His spider-sense went haywire, his HUD flickered, and for a terrifying second, his web-shooters sputtered, refusing to fire.\n",
            "\n",
            "\"Whoa, easy there, Tron!\" he yelled, barely ducking under a falling air-conditioning unit that had been dislodged by the digital surge.\n",
            "\n",
            "Just then, a voice, clear and sharp, cut through the din from a nearby rooftop. \"Hey! Over here!\"\n",
            "\n",
            "Spider-Man glanced over. A young woman, no older than himself, stood on the edge of the adjacent building. She wore a tech company ID badge around her neck, and in her hands was a tablet, its screen glowing with complex code.\n",
            "\n",
            "\"You need to overload his signal!\" she shouted, pointing at The Glitch. \"He's using a localized frequency jammer, piggybacking on the city's smart grid! Disrupt his primary channel!\"\n",
            "\n",
            "Spider-Man blinked. \"Uh... you lost me at 'localized frequency jammer,' but 'disrupt' I can do!\"\n",
            "\n",
            "He lunged, not at The Glitch, but at the massive satellite dish on top of the skyscraper, a primary node for the city's communication network. The Glitch, realizing his plan, tried to stop him, firing another wave of digital disruption. But Spider-Man, his spider-sense slightly clearer now, dodged and weaved, scaling the building's side with practiced ease.\n",
            "\n",
            "\"Hope this doesn't void anyone's warranty!\" he quipped, landing on the dish. He plunged his hands into the complex wiring, his enhanced strength and agility allowing him to quickly rip out key components, re-routing others in a desperate attempt to create a surge.\n",
            "\n",
            "The Glitch screamed in frustration, their device sputtering. The green light flickered, then died. The digital chaos across the city began to subside. Traffic lights blinked back to normal, ATMs settled down, and the giant screens returned to their advertisements.\n",
            "\n",
            "Spider-Man, slightly singed and covered in dust, leaped back to the rooftop. The Glitch, their device dead, crumpled to the ground, revealing a disgruntled-looking man with a severe case of unkempt hair.\n",
            "\n",
            "\"You really messed up my data stream, kid,\" the man grumbled.\n",
            "\n",
            "\"And you really messed up Mumbai's morning commute, pal,\" Spider-Man retorted. \"I think we're even.\"\n",
            "\n",
            "The young woman from the other rooftop, Aisha, walked over, a small smile playing on her lips. \"Impressive. Most people just try to punch him.\"\n",
            "\n",
            "\"Punching's usually my go-to,\" Spidey admitted, rubbing his neck. \"But you seemed to know what you were talking about. Thanks for the assist.\"\n",
            "\n",
            "\"Aisha Sharma,\" she introduced herself, extending a hand. \"I work for a network security firm. We've been tracking this guy, 'The Disruptor,' for weeks. He's been trying to crash global markets by targeting city infrastructures.\"\n",
            "\n",
            "\"Well, 'The Glitch' is apprehended,\" Spider-Man said, securing the bound villain with a generous amount of webbing. \"And I think I just learned more about networking than in all my high school tech classes combined.\"\n",
            "\n",
            "He spent the next hour helping Aisha explain the situation to the local authorities, who were understandably bewildered by the sudden appearance of a costumed hero and a tech terrorist. He even managed to snap a quick selfie with Aisha (she promised it was just for her personal collection).\n",
            "\n",
            "As the sun began to dip, painting the Mumbai sky in fiery hues of orange and purple, Spider-Man found himself perched on a high-rise, looking out over the now calm, bustling city. The air was still humid, but it felt cleaner, lighter.\n",
            "\n",
            "\"You know, New York's got its charm,\" he mused aloud, \"but there's something about this place. The energy, the history, the sheer… *life* of it. And the food. Definitely the food.\"\n",
            "\n",
            "He took a deep breath, the scent of spices and the distant sound of music filling his senses. He’d come to India by accident, fought a villain he never expected, and met an ally he never anticipated. It was a reminder that no matter how far he traveled, the call for help, the need for a friendly neighborhood Spider-Man, was truly universal.\n",
            "\n",
            "With a final, silent nod to the vibrant city below, Spider-Man launched himself into the deepening twilight, a red-and-blue streak against the Indian sky, leaving behind a city that would forever remember the day a friendly neighborhood web-slinger came to visit. He just hoped Tony wouldn't ask for a detailed report on his \"cultural experience.\" He'd probably just say it was... electrifying.\n",
            "The air hit Peter Parker like a humid, perfumed wall the moment he stepped off the plane at Narita. Not the familiar exhaust and hot dog scent of JFK, but something subtly different – a blend of ozone, damp earth, and an indefinable, clean sweetness. He took a deep breath, adjusted his glasses, and tried to look like any other tourist.\n",
            "\n",
            "He wasn't. He was Spider-Man, and he was in Japan.\n",
            "\n",
            "The official story was a \"cultural exchange program\" for advanced science students from Midtown High, but the real reason was a whisper on the global hero network: a new, highly unstable Stark Industries prototype, capable of manipulating localized gravity fields, had gone missing during transit and was last pinged somewhere in Tokyo. Nick Fury, in his usual charming way, had suggested Peter's \"unique skill set\" might be helpful.\n",
            "\n",
            "Getting through customs was surprisingly easy, even with his perpetually rumpled clothes. The bullet train to Tokyo was a blur of efficiency and quiet, a stark contrast to the cacophony of New York subways. Peter pressed his face to the window, watching the landscape shift from ordered farmland to a rising tide of concrete and glass.\n",
            "\n",
            "Tokyo was an assault on the senses. Neon lights pulsed in every direction, signs in kanji glowed like alien hieroglyphs, and the sheer volume of people in Shibuya Crossing was a human tsunami. Peter felt a strange mix of exhilaration and complete disorientation.\n",
            "\n",
            "\"Okay, Spidey,\" he muttered under his breath, ducking into a less crowded alleyway to pull out his suit from his backpack. \"Time to earn that frequent flyer mileage.\"\n",
            "\n",
            "Suit on, mask in place, he launched himself skyward, the familiar thwip of his web-shooters a comforting sound in this foreign land. The Tokyo skyline was breathtaking – a jagged crown of skyscrapers reaching for the stars. He swung, testing the air currents, marveling at the sheer scale of the city below. It was like New York, but… shinier. More vertical.\n",
            "\n",
            "His internal tracker, linked to the Stark prototype's last known location, led him towards the Shinjuku district, specifically a towering, multi-story electronics store that seemed to hum with latent energy.\n",
            "\n",
            "He landed silently on a rooftop, peering down. Below, the streets teemed with people, oblivious. His Spider-Sense, usually a frantic buzz in New York, was a low thrum here, almost peaceful. But as he focused on the target building, it began to prickle.\n",
            "\n",
            "A sudden explosion of glass and sparks erupted from the 15th floor. \"Showtime,\" Spidey muttered, launching himself into action.\n",
            "\n",
            "He crashed through the shattered window, rolling to his feet inside a scene of chaos. Alarms blared, smoke billowed, and terrified shoppers screamed. A figure in a sleek, obsidian suit, with glowing blue lines tracing its contours, was levitating a massive data server, its hands crackling with energy. This was no ordinary thief.\n",
            "\n",
            "\"Whoa there, pal! You really shouldn't lift with your back, you know? Especially when you're also lifting with your hands, and your feet, and… well, everything, really!\" Spidey quipped, dodging a sudden burst of energy that pulverized a display of anime figurines.\n",
            "\n",
            "The villain, who Peter later learned was a notorious tech-hacker and mercenary known as 'Kagami' (The Mirror), turned, his visor glowing. \"Spider-Man. You are far from home.\" His voice was synthesized, cold.\n",
            "\n",
            "\"Yeah, tell me about it! Jet lag is a killer. But hey, I'm a quick study. You planning on selling that server on eBay, or is this more of a 'villainous lair' decoration?\"\n",
            "\n",
            "Kagami didn't answer, instead unleashing a wave of distorted gravity. Peter felt the floor buckle, the air thicken, making it impossible to move. He barely managed to leap, sticking to the ceiling as Kagami tore through the building, grabbing the prototype from a reinforced display case.\n",
            "\n",
            "\"Hey! That's not yours! Finders keepers doesn't apply when you're also 'destroyers of property'!\"\n",
            "\n",
            "The chase was on. Kagami, using the gravity prototype, moved with impossible speed, phasing through walls, levitating over obstacles. Spidey, relying on his agility and quick thinking, swung through the shattered building, dodging falling debris and bursts of energy.\n",
            "\n",
            "The fight spilled out onto the streets, causing mass panic. Kagami, now fully powered, began to distort the very reality around them. Cars floated, streetlights bent at impossible angles, and the ground rippled like water. People screamed, caught in the bizarre gravitational shifts.\n",
            "\n",
            "\"Okay, this is new!\" Spidey shouted, narrowly avoiding a levitating vending machine. \"Seriously, dude, what's your deal? Are you trying to make everyone airsick?\"\n",
            "\n",
            "Just as Kagami prepared to unleash a devastating localized implosion, a blur of red and gold descended from the sky. A figure in a sleek, armored suit, adorned with traditional Japanese motifs, landed between Kagami and the terrified civilians. He wielded two shimmering katana blades, crackling with what looked like pure energy.\n",
            "\n",
            "\"The Crimson Blade,\" Kagami snarled, his voice tinged with annoyance.\n",
            "\n",
            "\"Your reign of chaos ends here, Kagami,\" the new hero declared, his voice deep and resonant. He moved with the grace of a dancer and the precision of a master swordsman, deflecting Kagami's gravity blasts with his blades.\n",
            "\n",
            "Spidey, momentarily stunned by the arrival of a local hero, quickly recovered. \"Alright, fancy pants! Need a hand? Or, you know, a web? I've got plenty!\"\n",
            "\n",
            "Crimson Blade glanced at him, a subtle nod. \"This one is… tenacious. Your assistance would be welcomed, *gaikokujin*.\"\n",
            "\n",
            "\"Gai-what now? Just call me Spidey. Or your friendly neighborhood Spider-Man. Whichever floats your boat, literally, with this guy around.\"\n",
            "\n",
            "Working together, they formed an unlikely but effective duo. Crimson Blade, with his focused, disciplined attacks, countered Kagami's raw power, while Spidey, with his unpredictable agility and web-slinging, kept the villain off balance and protected civilians. Spidey's webs, reinforced with his own strength, managed to briefly contain Kagami, allowing Crimson Blade to land a precise energy strike that overloaded the prototype.\n",
            "\n",
            "With a final shriek of static, Kagami's suit fizzled, and he crumpled to the ground, the stolen device clattering harmlessly away.\n",
            "\n",
            "The police arrived moments later, swarming the scene. Crimson Blade, after a brief, formal bow to Spidey, melted into the shadows, leaving the web-slinger to face the confused but grateful Japanese authorities.\n",
            "\n",
            "Later that night, perched on a rooftop overlooking the glittering expanse of Tokyo, Peter felt a profound sense of accomplishment. The prototype was secured, Kagami was in custody, and he'd even made a new heroic acquaintance.\n",
            "\n",
            "A quiet rustle behind him. Crimson Blade materialized from the shadows, his helmet retracted to reveal a stern, but not unkind, face. Akio.\n",
            "\n",
            "\"You fought well, Spider-Man,\" Akio said, his English precise. \"Your methods are… unconventional, but effective.\"\n",
            "\n",
            "\"Thanks! You too, Blade-Man. That sword trick was awesome. You got a secret dojo or something?\"\n",
            "\n",
            "Akio gave a small, almost imperceptible smile. \"My training is my own. But I confess, your quips were… distracting.\"\n",
            "\n",
            "\"Hey, it's my superpower! Humor and webs. The two pillars of my existence.\" Spidey chuckled. \"So, this Japan place. Pretty cool, huh? The food, the lights, the… giant robots I haven't seen yet but I'm holding out hope for.\"\n",
            "\n",
            "Akio looked out at the city. \"It is my home. And it is safe, thanks in part to your unexpected visit.\" He extended a hand. \"Thank you, Spider-Man.\"\n",
            "\n",
            "Peter shook it firmly. \"Anytime, Akio. Seriously. If you ever need a hand with, say, a giant lizard or something, just give me a call. I know a guy.\"\n",
            "\n",
            "As the first rays of dawn painted the sky in hues of orange and pink, Spider-Man swung away, leaving the silent sentinel of Tokyo behind. Japan had been an adventure, a challenge, and a revelation. It was a world away from home, but the heart of heroism, he realized, beat just as strong, no matter the language. And maybe, just maybe, he'd developed a craving for ramen that wouldn't go away anytime soon.\n",
            "The moment Peter Parker stepped off the plane in Rio de Janeiro, he felt it. Not the usual New York chill, but a humid embrace that clung to his skin, thick with the scent of salt, exhaust, and something sweet – perhaps tropical fruit or street food. The cacophony of Portuguese chatter, car horns, and distant samba music hit him like a physical wave.\n",
            "\n",
            "\"Okay, Brain-Trust,\" he muttered to himself, adjusting his glasses inside the bustling airport. \"Phase one: Blend in. Phase two: Find the guy who stole the Stark-tech prototype. Phase three: Don't get heatstroke in the suit.\"\n",
            "\n",
            "His mission was simple, on paper. A low-level tech thief, Silas Thorne, had made off with a crucial piece of Stark Industries’ latest clean energy tech and fled to Brazil. Tracking him had been tricky, but a faint energy signature had pinged here, to Rio.\n",
            "\n",
            "He found a quiet, out-of-the-way hostel in Santa Teresa, a bohemian neighborhood clinging to the hillsides. The view from his window, a sprawling panorama of terracotta roofs, lush greenery, and the glittering expanse of Guanabara Bay, was breathtaking. He wasted no time. As dusk painted the sky in fiery oranges and purples, Spider-Man launched himself from the hostel's rooftop.\n",
            "\n",
            "The first web-swing through Rio was an experience unlike any other. New York had its concrete canyons and dizzying heights. Rio had… everything. He swung past the iconic, tiled sidewalks of Copacabana, the rhythmic thud of a distant drum circle vibrating through his chest. He zipped over bustling markets, the air thick with the smell of grilled meat and exotic spices. Palm trees replaced lamp posts, and instead of uniform skyscrapers, he navigated around colorful, haphazardly built favelas that climbed the hillsides like vibrant, organic sculptures.\n",
            "\n",
            "\"Okay, this is… different,\" he quipped, narrowly avoiding a clothesline strung between two buildings. \"Less predictable, more… samba-friendly.\"\n",
            "\n",
            "His Spider-Sense, usually a reliable guide, was on overdrive. The sheer density of life, the constant movement, the vibrant energy of the city was a sensory overload. He had to focus, filtering out the general hum to pinpoint Thorne's specific energy signature.\n",
            "\n",
            "He traced it to a high-rise in Ipanema, a sleek, modern building that stood out amidst the older architecture. Peeking through a window, he saw Thorne, hunched over a workbench, tinkering with the glowing Stark prototype.\n",
            "\n",
            "\"Gotcha, you sneaky little… wait, is that a caipirinha?\" Spidey muttered, noticing the glass beside Thorne. \"Multitasking, I see. Classy.\"\n",
            "\n",
            "He silently slipped inside, but Thorne, surprisingly alert, spun around, a small, multi-legged drone whirring to life in his hand. \"Spider-Man! Knew you'd follow!\" Thorne yelled, activating the drone.\n",
            "\n",
            "The chase was on. Thorne, surprisingly agile, darted through the building, the drone buzzing around Spidey, firing small, concussive blasts. Spidey dodged, weaved, and quipped. \"Seriously, dude? You come all the way to Brazil just to get caught? There are so many better ways to spend a Tuesday night!\"\n",
            "\n",
            "Thorne burst out onto a balcony, leaping onto a zipline that stretched precariously between two buildings, leading towards the densely packed favela below. \"Try catching me in the *comunidade*, wall-crawler!\"\n",
            "\n",
            "\"Oh, come on!\" Spidey groaned, swinging after him. \"That's just rude to the neighborhood!\"\n",
            "\n",
            "The favela was a labyrinth. Narrow, winding alleys, steep staircases, vibrant murals covering every available surface. Music spilled from open windows, children played football in improvised courts, and the smell of cooking food filled the air. Spidey found himself having to be extra careful, not wanting to cause any collateral damage or disrupt the lives of the residents. His Spider-Sense was screaming, not just from Thorne, but from the sheer volume of people, the hidden corners, the unexpected turns.\n",
            "\n",
            "Thorne, surprisingly, seemed to know the shortcuts, darting through a bustling market, knocking over a stack of colorful fruit. \"Hey! Watch it, pal!\" Spidey yelled, quickly webbing the fruit back into place, earning a confused but grateful look from the vendor.\n",
            "\n",
            "He spotted Thorne scaling a wall, heading towards one of the highest points. Spidey followed, his movements a blur of red and blue against the backdrop of vibrant street art. He heard shouts, laughter, and then, a distinct rhythm.\n",
            "\n",
            "He landed on a small, elevated plaza, where a group of young men were practicing capoeira, their movements a mesmerizing blend of martial arts, dance, and acrobatics. Thorne was trying to slip past them, but his frantic scramble caught their attention.\n",
            "\n",
            "\"Ei! What's wrong with him?\" one of the capoeiristas called out, his leg flashing in a high kick that narrowly missed Thorne.\n",
            "\n",
            "\"Just a little 'misunderstanding' about borrowed tech!\" Spidey yelled back, as Thorne tried to scramble over a low wall.\n",
            "\n",
            "\"You're not going anywhere, pal!\" Spidey launched himself, a web hitting Thorne's ankle, yanking him back. Thorne stumbled, landing right in the middle of the capoeira circle.\n",
            "\n",
            "As Spidey landed, he found himself facing not just Thorne, but a circle of curious, agile Brazilians. \"Okay, so this isn't awkward at all,\" he muttered.\n",
            "\n",
            "Thorne tried to make a break for it again, but one of the capoeiristas, a lean man with quick reflexes, executed a sweeping leg movement, tripping Thorne neatly. Another caught the falling prototype.\n",
            "\n",
            "\"Obrigado,\" Spidey said, nodding, then quickly realizing his Portuguese was limited. \"Uh, thanks! You guys are… really good at… moving!\"\n",
            "\n",
            "The capoeiristas chuckled. \"Just training, amigo,\" one of them said, handing him the prototype. \"He was disrupting our *roda*.\"\n",
            "\n",
            "Spidey quickly webbed Thorne to a nearby lamppost, making sure he was secure. \"Well, he won't be disrupting anything for a while. You guys were awesome! Like, really, really awesome. Can you teach me that move where you spin on your hands and kick?\"\n",
            "\n",
            "They laughed, and one offered, \"Maybe next time, Homem-Aranha!\"\n",
            "\n",
            "He spent a few more minutes answering questions, posing for a few quick phone pictures (mostly with kids who recognized him from the internet), and even got offered a small, delicious-looking pastry (which he regretfully declined, citing his \"strict superhero diet\").\n",
            "\n",
            "As the sun began to set, casting long shadows over the city, Spider-Man swung to the very top of Christ the Redeemer. He sat on the immense statue's shoulder, looking out over the twinkling lights of Rio. The city pulsed with an energy he'd never experienced, a vibrant, resilient spirit that hummed beneath the surface.\n",
            "\n",
            "\"New York's great, don't get me wrong,\" he mused aloud, the warm breeze ruffling his mask. \"But there's something about this place. The music, the people, the way they just… live. Even the villains are more culturally aware.\" He paused. \"Though I'm still not sure about the caipirinha for a tech thief. Seems a bit much for a Tuesday.\"\n",
            "\n",
            "With a final, wistful glance at the sprawling, beautiful city, Spider-Man launched himself into the Brazilian night, leaving behind a slightly more secure Rio, and taking with him a newfound appreciation for samba, capoeira, and the incredible, chaotic beauty of the Marvel Universe's most vibrant city. He also made a mental note to ask Tony for a heat-resistant suit for future international excursions.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 3 — Simple LLM Chains <a name=\"lesson-3\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to connect a **prompt template** and a **model** into a **chain** so we can run the entire prompt → model → output flow in a single, reusable object.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "- **What is an LLM Chain?**  \n",
        "  A chain in LangChain is a sequence of components that process inputs and produce outputs.  \n",
        "  The simplest LLM chain has:\n",
        "  1. A **PromptTemplate**\n",
        "  2. An **LLM model** (in our case, Gemini)\n",
        "  3. (Optionally) post-processing logic\n",
        "\n",
        "- **Why use LLM Chains?**\n",
        "  - Encapsulates the prompt + model into one reusable unit.\n",
        "  - Makes code cleaner and easier to maintain.\n",
        "  - Works well with batch processing and integration into larger workflows.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 Key Points\n",
        "1. The **LangChain Expression Language (LCEL)** lets us “pipe” components together using `|`.\n",
        "2. Once we have a chain, we can run it with `.invoke()` (single input) or `.batch()` (multiple inputs).\n",
        "3. Chains can be expanded later to include memory, tools, or retrieval.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example (Gemini-Only)\n",
        "\n",
        "```python\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Step 1: Create a prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"topic\", \"tone\"],\n",
        "    template=\"Write a {tone} LinkedIn post about {topic}.\"\n",
        ")\n",
        "\n",
        "# Step 2: Initialize Gemini model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "# Step 3: Pipe prompt into model to form a chain\n",
        "chain = prompt | model\n",
        "\n",
        "# Step 4: Run the chain\n",
        "result = chain.invoke({\"topic\": \"AI-powered analytics\", \"tone\": \"professional\"})\n",
        "print(result.content)\n",
        "```\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### 🧪 Time to Practice — Lesson 3\n",
        "\n",
        "**Goal:**  \n",
        "We will practice creating a simple LLM chain that combines a `PromptTemplate` and the Gemini model into a single reusable workflow.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Basic Interview Question Generator**\n",
        "1. Create a `PromptTemplate` with:\n",
        "   - Variables: `{role}` and `{skill}`\n",
        "   - Template: `\"Generate one behavioral interview question for a {role} role that tests {skill}.\"`\n",
        "2. Initialize `ChatGoogleGenerativeAI` with:\n",
        "   - `model=\"gemini-1.5-flash\"`\n",
        "   - `temperature=0.5`\n",
        "3. Create a chain by piping the prompt into the model.\n",
        "4. Invoke the chain with:\n",
        "   - `role`: `\"Data Scientist\"`\n",
        "   - `skill`: `\"communication\"`\n",
        "5. Print the generated interview question.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 2 — Multiple Skills**\n",
        "1. Create a Python list of at least **three skills** (e.g., `[\"communication\", \"problem-solving\", \"leadership\"]`).\n",
        "2. Loop through the skills list.\n",
        "3. For each skill, run the chain and print the question.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 3 — Variety with Temperature**\n",
        "1. Run the same chain with:\n",
        "   - `temperature=0.2` (more deterministic)\n",
        "   - `temperature=0.8` (more creative)\n",
        "2. Compare how the style and wording of questions change.\n",
        "\n",
        "---\n",
        "\n",
        "> When we finish, we’ll discuss how chaining improves workflow reusability and makes it easy to adapt the same logic for multiple inputs.\n"
      ],
      "metadata": {
        "id": "BbOmaENWPjap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Step 1: Create a prompt template\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"role\", \"skill\"],\n",
        "    template=\"Generate one behavioral interview question for a {role} role that tests {skill}.\"\n",
        ")\n",
        "\n",
        "# Step 2: Initialize Gemini model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.5)\n",
        "\n",
        "# Step 3: Pipe prompt into model to form a chain\n",
        "chain = prompt | model\n",
        "\n",
        "# Step 4: Run the chain\n",
        "result = chain.invoke({\"role\": \"Data Scientist\", \"skill\": \"communication\"})\n",
        "print(result.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEPYVNRgPj3K",
        "outputId": "fe306bfa-1f50-4184-e4d3-cfc40bfe4094"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Describe a time you had to explain a complex technical finding or analysis to a non-technical audience (e.g., executives, stakeholders).  What approach did you take, and what were the results?  What did you learn from that experience about communicating complex information effectively?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 Loop\n",
        "\n",
        "skills = [\"communication\", \"problem-solving\", \"leadership\"]\n",
        "\n",
        "for skill in skills:\n",
        "  print(skill,\": \",chain.invoke({\"role\": \"Data Scientist\", \"skill\": skill}).content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n7Iw37PTSWT7",
        "outputId": "388b6d79-1abc-4639-912b-6450ecdac18e"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "communication :  \"Describe a time you had to explain a complex technical finding or analysis to a non-technical audience (e.g., executives, stakeholders).  What approach did you take, and what was the outcome?  Focus on the communication strategies you employed and how you adapted your message based on your audience.\"\n",
            "problem-solving :  Tell me about a time you had to analyze a dataset with significant missing data.  Describe the approach you took to handle the missing values, the rationale behind your choices, and the impact your decision had on the final results.  What would you do differently if you had to repeat the process?\n",
            "leadership :  Tell me about a time you had to lead a team to overcome a significant challenge in a data project where there were conflicting priorities or differing opinions among team members.  How did you navigate those differences to achieve a successful outcome?  What was your approach to ensuring everyone felt heard and valued, even if their ideas weren't ultimately implemented?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 Different temperatures\n",
        "\n",
        "def run_with_temperature(temp):\n",
        "    model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=temp)\n",
        "    chain = prompt | model\n",
        "    result = chain.invoke({\"role\": \"Data Scientist\", \"skill\": \"Leadership\"})\n",
        "    print(f\"--- Temperature {temp} ---\")\n",
        "    print(result.content, \"\\n\")\n",
        "\n",
        "for t in [0.2, 0.5, 0.8,1]:\n",
        "    run_with_temperature(t)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C-_h3Ji4SM_w",
        "outputId": "e06399fa-c4fa-4ed7-93f9-fba41912ed24"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Temperature 0.2 ---\n",
            "Tell me about a time you had to lead a team through a complex data analysis project where there were conflicting priorities or disagreements among team members regarding the approach. How did you navigate these challenges and ensure the project stayed on track and delivered valuable results? \n",
            "\n",
            "--- Temperature 0.5 ---\n",
            "Tell me about a time you had to lead a team through a complex data analysis project where there were conflicting priorities or differing opinions on the best approach.  How did you navigate those challenges and ensure the team remained productive and collaborative while still delivering high-quality results? \n",
            "\n",
            "--- Temperature 0.8 ---\n",
            "\"Tell me about a time you had to lead a team through a complex data analysis project where there were conflicting priorities or disagreements among team members regarding the approach.  How did you navigate these challenges, and what was the outcome?\" \n",
            "\n",
            "--- Temperature 1 ---\n",
            "Tell me about a time you had to lead a team to overcome a significant challenge in a data science project, where there were conflicting priorities or approaches.  Describe the challenge, your approach to leading the team through the conflict, and the ultimate outcome.  What did you learn from this experience? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 4 — Adding Memory to Conversations <a name=\"lesson-4\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to add **memory** to a LangChain conversation so the model can remember earlier exchanges and use them in later responses.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "- **What is Memory in LangChain?**  \n",
        "  Memory stores parts of the conversation and feeds them back into the prompt on future calls.\n",
        "\n",
        "- **Why use it?**\n",
        "  - Without memory, each call is independent — the model forgets what we said before.\n",
        "  - With memory, we can build **chatbots**, **assistants**, and **multi-turn conversations** that feel natural and coherent.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 Key Points\n",
        "1. Memory is **separate from the LLM** — it’s a component we attach to chains or agents.\n",
        "2. Common memory types:\n",
        "   - `ConversationBufferMemory` — stores the entire conversation verbatim (simplest).\n",
        "   - `ConversationSummaryMemory` — stores a summarized history to save tokens.\n",
        "3. Memory automatically injects stored history into the **prompt** as a variable.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example\n"
      ],
      "metadata": {
        "id": "XnTfZIcFT5rl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Step 1: Define prompt with placeholders\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    template=(\n",
        "        \"The following is a friendly conversation between a human and AI.\\n\"\n",
        "        \"Conversation so far:\\n{history}\\n\"\n",
        "        \"Human: {input}\\n\"\n",
        "        \"AI:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 2: Create memory object\n",
        "memory = ConversationBufferMemory(memory_key=\"history\")\n",
        "\n",
        "# Step 3: Initialize Gemini model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "# Step 4: Create chain\n",
        "chain = LLMChain(llm=model, prompt=prompt, memory=memory)\n",
        "\n",
        "# Step 5: Custom function to debug and run\n",
        "def run_and_debug(user_input):\n",
        "    # Get current history from memory\n",
        "    current_history = memory.load_memory_variables({}).get(\"history\", \"\")\n",
        "\n",
        "    # Show the actual prompt sent to Gemini\n",
        "    print(\"\\n--- Prompt Sent to Model ---\")\n",
        "    print(prompt.format(history=current_history, input=user_input))\n",
        "\n",
        "    # Run chain and print result\n",
        "    response = chain.run(input=user_input)\n",
        "    print(\"\\n--- Model Response ---\")\n",
        "    print(response)\n",
        "\n",
        "# Simulate conversation\n",
        "run_and_debug(\"Hi, my name is Alex.\")\n",
        "run_and_debug(\"What is my name?\")\n",
        "run_and_debug(\"Suggest a hobby I might enjoy.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6RnZawXT6Jm",
        "outputId": "01835192-66e1-495d-dbac-dbefa4b3a2e1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2295954925.py:18: LangChainDeprecationWarning: Please see the migration guide at: https://python.langchain.com/docs/versions/migrating_memory/\n",
            "  memory = ConversationBufferMemory(memory_key=\"history\")\n",
            "/tmp/ipython-input-2295954925.py:24: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
            "  chain = LLMChain(llm=model, prompt=prompt, memory=memory)\n",
            "/tmp/ipython-input-2295954925.py:36: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  response = chain.run(input=user_input)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "\n",
            "Human: Hi, my name is Alex.\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "AI: Hello Alex, it's nice to meet you.  How can I help you today?\n",
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "Human: Hi, my name is Alex.\n",
            "AI: AI: Hello Alex, it's nice to meet you.  How can I help you today?\n",
            "Human: What is my name?\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "AI: Your name is Alex.\n",
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "Human: Hi, my name is Alex.\n",
            "AI: AI: Hello Alex, it's nice to meet you.  How can I help you today?\n",
            "Human: What is my name?\n",
            "AI: AI: Your name is Alex.\n",
            "Human: Suggest a hobby I might enjoy.\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "AI: That depends on what you like!  To give you the best suggestion, tell me a little about your interests. Do you prefer indoor or outdoor activities? Do you like being creative, competitive, or relaxing?  Do you prefer solitary activities or group activities?  The more information you give me, the better I can help!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 4\n",
        "\n",
        "**Goal:**  \n",
        "We will create a multi-turn conversation chain that remembers past exchanges and optionally displays the full prompt sent to Gemini for debugging.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Basic Memory Chat**\n",
        "1. Use `ConversationBufferMemory` with `memory_key=\"history\"`.\n",
        "2. Create a `PromptTemplate` with:\n",
        "   - `{history}` for past conversation.\n",
        "   - `{input}` for the new user message.\n",
        "3. Attach the memory to an `LLMChain` with `ChatGoogleGenerativeAI`.\n",
        "4. Simulate **three turns**:\n",
        "   - Turn 1: Introduce yourself and state your favorite programming language.\n",
        "   - Turn 2: Ask the model to recall your favorite programming language.\n",
        "   - Turn 3: Ask it to suggest a project in that language.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 2 — Using ConversationSummaryMemory**\n",
        "1. Replace `ConversationBufferMemory` with `ConversationSummaryMemory`.\n",
        "2. Keep the same three-turn conversation.\n",
        "3. Compare:\n",
        "   - Does the model still remember your favorite programming language?\n",
        "   - How does the stored history look compared to the full buffer?\n",
        "\n",
        "---\n",
        "\n",
        "> **Tip:**  \n",
        "> Prompt debugging is a powerful way to understand what the LLM “sees” on each turn and why it responds the way it does.\n"
      ],
      "metadata": {
        "id": "wnMq-FfOfmfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Part 1\n",
        "\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "\n",
        "# Step 1: Define prompt with placeholders\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    template=(\n",
        "        \"The following is a friendly conversation between a human and AI.\\n\"\n",
        "        \"Conversation so far:\\n{history}\\n\"\n",
        "        \"Human: {input}\\n\"\n",
        "        \"AI:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Step 2: Create memory object\n",
        "memory = ConversationBufferMemory(memory_key=\"history\")\n",
        "\n",
        "# Step 3: Initialize Gemini model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "# Step 4: Create chain\n",
        "chain = LLMChain(llm=model, prompt=prompt, memory=memory)\n",
        "\n",
        "# Step 5: Custom function to debug and run\n",
        "def run_and_debug(user_input):\n",
        "    # Get current history from memory\n",
        "    current_history = memory.load_memory_variables({}).get(\"history\", \"\")\n",
        "\n",
        "    # Show the actual prompt sent to Gemini\n",
        "    print(\"\\n--- Prompt Sent to Model ---\")\n",
        "    print(prompt.format(history=current_history, input=user_input))\n",
        "\n",
        "    # Run chain and print result\n",
        "    response = chain.run(input=user_input)\n",
        "    print(\"\\n--- Model Response ---\")\n",
        "    print(response)\n",
        "\n",
        "# Simulate conversation\n",
        "run_and_debug(\"Hi, my name is Sudeep. My Favourite Programming Language is Python\")\n",
        "run_and_debug(\"What is my favourite Programming Language?\")\n",
        "run_and_debug(\"Suggest a project I might enjoy in my favourite programming language?.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qy8V323iaclG",
        "outputId": "2a3b731c-85a0-4699-992d-d49ee1dd4d23"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "\n",
            "Human: Hi, my name is Sudeep. My Favourite Programming Language is Python\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "AI: Hi Sudeep! It's nice to meet you. Python is a great choice for a favorite programming language.  It's versatile and widely used. What do you enjoy most about using Python?\n",
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "Human: Hi, my name is Sudeep. My Favourite Programming Language is Python\n",
            "AI: AI: Hi Sudeep! It's nice to meet you. Python is a great choice for a favorite programming language.  It's versatile and widely used. What do you enjoy most about using Python?\n",
            "Human: What is my favourite Programming Language?\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "Your favorite programming language is Python.\n",
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "Human: Hi, my name is Sudeep. My Favourite Programming Language is Python\n",
            "AI: AI: Hi Sudeep! It's nice to meet you. Python is a great choice for a favorite programming language.  It's versatile and widely used. What do you enjoy most about using Python?\n",
            "Human: What is my favourite Programming Language?\n",
            "AI: Your favorite programming language is Python.\n",
            "Human: Suggest a project I might enjoy in my favourite programming language?.\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "Given your love for Python's versatility, here are a few project suggestions catering to different skill levels:\n",
            "\n",
            "**Beginner:**\n",
            "\n",
            "* **Simple Text-Based Adventure Game:**  This is a classic beginner project. You'll learn about variables, loops, conditional statements, and potentially user input/output.  You can build a small story with choices that lead to different outcomes.\n",
            "* **Basic To-Do List Application:** This involves creating a program that lets users add, remove, and view tasks.  It's a good introduction to working with lists or other data structures.\n",
            "* **Number Guessing Game:** The computer generates a random number, and the user tries to guess it.  This is a fun way to practice loops and conditional logic.\n",
            "\n",
            "**Intermediate:**\n",
            "\n",
            "* **Web Scraper:** Learn to extract data from websites using libraries like `Beautiful Soup` and `requests`.  You could scrape product information, news articles, or anything that interests you. (Remember to respect website terms of service and robots.txt.)\n",
            "* **Simple Web Application with Flask or Django:** Build a basic web application using one of Python's popular web frameworks.  This could be a blog, a simple to-do list app with a web interface, or a personal portfolio website.\n",
            "* **Data Analysis Project:**  Use libraries like `pandas` and `NumPy` to analyze a dataset of your choosing.  This could be anything from analyzing movie ratings to exploring weather data.  You can visualize your findings using `matplotlib` or `seaborn`.\n",
            "\n",
            "**Advanced:**\n",
            "\n",
            "* **Machine Learning Project:** Explore machine learning using libraries like `scikit-learn` or `TensorFlow/Keras`.  You could build a model for image classification, sentiment analysis, or something else that interests you.\n",
            "* **Desktop Application with Tkinter or PyQt:** Create a more sophisticated desktop application with a graphical user interface (GUI).\n",
            "* **Contribute to an Open Source Project:** Find a project on GitHub that aligns with your interests and contribute by fixing bugs, adding features, or improving documentation.\n",
            "\n",
            "\n",
            "To choose the best project, consider:\n",
            "\n",
            "* **Your current skill level:** Start with something manageable and gradually increase the complexity.\n",
            "* **Your interests:** Choose a project that genuinely excites you.  This will keep you motivated throughout the process.\n",
            "* **Available resources:**  Make sure you have access to the necessary libraries and data.\n",
            "\n",
            "Let me know what kind of project sounds most appealing, and I can offer more specific guidance!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationSummaryMemory\n",
        "from langchain.chains import LLMChain\n",
        "\n",
        "# Prompt\n",
        "prompt = PromptTemplate(\n",
        "    input_variables=[\"history\", \"input\"],\n",
        "    template=(\n",
        "        \"The following is a friendly conversation between a human and AI.\\n\"\n",
        "        \"Conversation so far:\\n{history}\\n\"\n",
        "        \"Human: {input}\\n\"\n",
        "        \"AI:\"\n",
        "    )\n",
        ")\n",
        "\n",
        "# Model for both chat and summarization (you may also use two separate instances)\n",
        "chat_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "summary_llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.0)  # deterministic for summaries\n",
        "\n",
        "# Memory requires an LLM\n",
        "memory = ConversationSummaryMemory(llm=summary_llm, memory_key=\"history\")\n",
        "\n",
        "# Chain with memory\n",
        "chain = LLMChain(llm=chat_llm, prompt=prompt, memory=memory)\n",
        "\n",
        "# Debug helper\n",
        "def run_and_debug(user_input: str):\n",
        "    current_history = memory.load_memory_variables({}).get(\"history\", \"\")\n",
        "    print(\"\\n--- Prompt Sent to Model ---\")\n",
        "    print(prompt.format(history=current_history, input=user_input))\n",
        "    response = chain.run(input=user_input)\n",
        "    print(\"\\n--- Model Response ---\")\n",
        "    print(response)\n",
        "\n",
        "# Conversation\n",
        "run_and_debug(\"Hi, my name is Sudeep. My favorite programming language is Python.\")\n",
        "run_and_debug(\"What is my favorite programming language?\")\n",
        "run_and_debug(\"Suggest a project I might enjoy in my favorite programming language.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I30EuV3PgjN0",
        "outputId": "155bcda9-9e30-4b08-e8f3-2eedd8243ab0"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "\n",
            "Human: Hi, my name is Sudeep. My favorite programming language is Python.\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "Hi Sudeep!  It's nice to meet you. Python's a great choice – it's versatile and widely used.  What are you working on with Python at the moment, if you don't mind me asking?\n",
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "Sudeep introduced himself, stating his name is Sudeep and that his favorite programming language is Python. The AI responded with a greeting, complimented his choice of Python, noting its versatility and widespread use, and then asked about his current Python projects.\n",
            "Human: What is my favorite programming language?\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "You said your favorite programming language is Python.\n",
            "\n",
            "--- Prompt Sent to Model ---\n",
            "The following is a friendly conversation between a human and AI.\n",
            "Conversation so far:\n",
            "Sudeep introduced himself as Sudeep, stating his favorite programming language is Python. The AI greeted him, complimented his choice of Python, highlighting its versatility and popularity, and inquired about his current Python projects.  The AI then correctly recalled that Sudeep's favorite programming language is Python.\n",
            "Human: Suggest a project I might enjoy in my favorite programming language.\n",
            "AI:\n",
            "\n",
            "--- Model Response ---\n",
            "Knowing your favorite language is Python, and wanting to suggest something enjoyable, I have a few ideas depending on your current skill level and interests:\n",
            "\n",
            "**Beginner-Friendly:**\n",
            "\n",
            "* **A simple text-based adventure game:** This is a classic beginner project that lets you practice working with user input, conditional statements, and loops. You could create a choose-your-own-adventure style game with different paths and outcomes.  It's a fun way to learn about game logic and user interaction.\n",
            "* **A basic to-do list application:** This project allows you to practice file I/O (reading and writing to files) to save and load your to-do items. You can also incorporate features like adding, deleting, and marking tasks as complete.  This project teaches you about data management and user interface design (even a simple text-based one).\n",
            "* **A number guessing game:**  This is a great way to practice using random number generation and loops. The computer can pick a random number, and the user tries to guess it, with feedback on whether their guess is too high or too low. This is a quick project that reinforces fundamental programming concepts.\n",
            "\n",
            "**Intermediate:**\n",
            "\n",
            "* **A web scraper:**  Using libraries like `BeautifulSoup` and `requests`, you can scrape data from websites.  This is a great way to learn about web technologies and data extraction. (Remember to respect the website's `robots.txt` and terms of service!)  You could scrape product information, news articles, or anything else that interests you.\n",
            "* **A simple web application using Flask or Django:**  If you're interested in web development, building a small web application is a rewarding project.  Flask is a lightweight framework, while Django is more robust. You could build a blog, a simple to-do list app (more advanced than the beginner version), or a personal portfolio website.\n",
            "* **Data analysis project using Pandas and Matplotlib:**  If you have some data you're interested in analyzing (e.g., from a CSV file or a website), you can use Pandas to manipulate the data and Matplotlib to create visualizations. This project allows you to practice data manipulation and visualization skills.\n",
            "\n",
            "\n",
            "**To help me narrow it down, tell me:**\n",
            "\n",
            "* **What aspects of programming do you enjoy most?** (e.g.,  game development, web development, data analysis, etc.)\n",
            "* **What's your current skill level in Python?** (Beginner, intermediate, advanced)\n",
            "* **Are there any specific areas you'd like to learn more about?**\n",
            "\n",
            "\n",
            "The more information you provide, the better I can tailor a suggestion to your interests and abilities.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 5 — Multiple Chains & Sequential Execution <a name=\"lesson-5\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to run **multiple LangChain chains in sequence**, passing the output of one chain as the input to another.  \n",
        "This is useful for **multi-step workflows**, where each step builds on the result of the previous step.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### **What is an `LLMChain`?**\n",
        "- An **LLMChain** is the most common LangChain building block.\n",
        "- It’s a **wrapper** that connects:\n",
        "  1. A **PromptTemplate** (instructions + variables).\n",
        "  2. An **LLM model** (e.g., Gemini, OpenAI).\n",
        "- When you call `.run()` or `.invoke()`, it:\n",
        "  - Fills the prompt with your inputs.\n",
        "  - Sends it to the LLM.\n",
        "  - Returns the model’s output.\n",
        "\n",
        "**Why use it?**\n",
        "- Keeps prompt logic and LLM configuration in one place.\n",
        "- Makes the chain **reusable** across workflows.\n",
        "\n",
        "---\n",
        "\n",
        "#### **What is a `SimpleSequentialChain`?**\n",
        "- A **SimpleSequentialChain** runs **two or more LLMChains back-to-back**.\n",
        "- It assumes:\n",
        "  - Each chain’s output is **a single string**.\n",
        "  - That string is passed as the **only input** to the next chain.\n",
        "\n",
        "**When to use:**\n",
        "- When your steps pass just **one string result** to the next step.\n",
        "- For more complex workflows (multiple variables), you’d use `SequentialChain`.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 Key Points\n",
        "1. `LLMChain` = Prompt + LLM → single callable unit.\n",
        "2. `SimpleSequentialChain` = Chain of `LLMChain` objects, passing output sequentially.\n",
        "3. Each chain should have compatible input/output formats for smooth passing.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example (Gemini-Only, SimpleSequentialChain)\n",
        "\n"
      ],
      "metadata": {
        "id": "J8spCnYOiHdE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# Step 1: Initialize the model (can be reused across chains)\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.7)\n",
        "\n",
        "# Step 2: First chain → Idea generation\n",
        "prompt_idea = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Generate one creative startup idea about {topic}.\"\n",
        ")\n",
        "chain_idea = LLMChain(llm=model, prompt=prompt_idea)\n",
        "\n",
        "# Step 3: Second chain → Elevator pitch creation\n",
        "prompt_pitch = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Write a short, engaging elevator pitch for this startup idea: {text}\"\n",
        ")\n",
        "chain_pitch = LLMChain(llm=model, prompt=prompt_pitch)\n",
        "\n",
        "# Step 4: Combine into a SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain_idea, chain_pitch])\n",
        "\n",
        "# Step 5: Run the combined chain\n",
        "result = overall_chain.run(\"AI-powered analytics\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVSZ-GPzg5Ne",
        "outputId": "5e649086-cac2-4b02-f000-fb25179e73d6"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Is your non-profit drowning in data but struggling to tell your impact story?  ImpactVerse uses AI to transform your numbers into compelling narratives and stunning visuals, automatically generating reports, fundraising materials, and even predicting future outcomes.  We empower non-profits to connect with donors and achieve greater success – all at an affordable price.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 5\n",
        "\n",
        "**Goal:**  \n",
        "We will practice building a multi-step workflow using `LLMChain` and `SimpleSequentialChain` so that one chain’s output becomes the next chain’s input.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Blog Post Workflow**\n",
        "1. **First Chain** — Blog Outline Generator:\n",
        "   - Input variable: `{topic}`\n",
        "   - Task: Generate a blog post outline in bullet points about the topic.\n",
        "2. **Second Chain** — Intro Paragraph Writer:\n",
        "   - Input variable: `{text}`\n",
        "   - Task: Write a short introductory paragraph based on the outline.\n",
        "3. Combine both chains using `SimpleSequentialChain`.\n",
        "4. Run the workflow with:\n",
        "   - `topic = \"The Future of Comedy in the Age of AI\"`\n",
        "5. Print the final output.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 2 — Experiment with Temperature**\n",
        "1. Run the same workflow with:\n",
        "   - Both chains having `temperature=0.2` (more deterministic).\n",
        "   - Both chains having `temperature=0.8` (more creative).\n",
        "2. Compare how the structure, detail, and tone change.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 3 — Three-Step Workflow (Optional)**\n",
        "1. Add a third chain:\n",
        "   - Input variable: `{text}`\n",
        "   - Task: Summarize the blog post into **a single engaging tweet**.\n",
        "2. Update the `SimpleSequentialChain` to include all three chains.\n",
        "3. Run the workflow end-to-end and check for coherence across all steps.\n",
        "\n",
        "---\n",
        "\n",
        "> **Tip:**  \n",
        "> Keep your prompt instructions very clear for each step so the model knows exactly what’s expected.\n"
      ],
      "metadata": {
        "id": "cYhfZ00FlOW_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains import LLMChain, SimpleSequentialChain\n",
        "\n",
        "# Step 1: Initialize the model (can be reused across chains)\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.9)\n",
        "\n",
        "# Step 2: First chain → Outline generator\n",
        "prompt_blog_outline = PromptTemplate(\n",
        "    input_variables=[\"topic\"],\n",
        "    template=\"Generate a blog post outline in bullet points about the topic: {topic}.\"\n",
        ")\n",
        "chain_blog_outline = LLMChain(llm=model, prompt=prompt_blog_outline)\n",
        "\n",
        "# Step 3: Second chain → Elevator pitch creation\n",
        "prompt_blog_paragraph = PromptTemplate(\n",
        "    input_variables=[\"text\"],\n",
        "    template=\"Write a short blog post based on the outline: {text}\"\n",
        ")\n",
        "chain_blog_paragraph = LLMChain(llm=model, prompt=prompt_blog_paragraph)\n",
        "\n",
        "\n",
        "prompt_blog_tweet = PromptTemplate(\n",
        "     input_variables=[\"text\"],\n",
        "    template=\" Summarize the blog post into a single engaging tweet. Here's the blog Post content: {text}.\"\n",
        ")\n",
        "chain_blog_tweet = LLMChain(llm = model,prompt = prompt_blog_tweet )\n",
        "\n",
        "# Step 4: Combine into a SimpleSequentialChain\n",
        "overall_chain = SimpleSequentialChain(chains=[chain_blog_outline, chain_blog_paragraph,chain_blog_tweet ])\n",
        "\n",
        "# Step 5: Run the combined chain\n",
        "result = overall_chain.run(\"The Future of Comedy in the Age of AI\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WfTl8FnCiH3q",
        "outputId": "b49ef65a-6b21-4751-cab2-a5487ca8326a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Can AI write jokes?  Yes, but can it *be* funny? 🤔  A new blog post explores AI's growing role in comedy—from writing scripts to tailoring shows—but argues the human element, with its emotional depth & lived experience, remains irreplaceable.  #AI #comedy #artificialintelligence #humor\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 6 — Introduction to Agents <a name=\"lesson-6\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn what **agents** are in LangChain, how they work, and why they’re different from fixed chains.  \n",
        "Agents let the LLM **decide at runtime** what steps to take and which tools to use to accomplish a goal.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### **What is an Agent?**\n",
        "- An **Agent** is a LangChain component that:\n",
        "  1. Gets a **goal** or question from the user.\n",
        "  2. Chooses which **tool(s)** to use (search, calculator, database, etc.).\n",
        "  3. Decides **the order** of tool usage.\n",
        "  4. Loops until the goal is met.\n",
        "\n",
        "#### **Why use Agents?**\n",
        "- **Chains** are static: they run the same steps every time.\n",
        "- **Agents** are dynamic: they reason about the problem, decide the next step, and choose tools as needed.\n",
        "- Great for:\n",
        "  - Tasks with uncertain steps.\n",
        "  - Real-time data fetching.\n",
        "  - Multi-step problem solving.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 New Concepts in This Lesson\n",
        "\n",
        "#### 1. **`Tool`**\n",
        "- A `Tool` in LangChain is a wrapper around a Python function that the LLM can call.\n",
        "- The tool has:\n",
        "  - `name`: Identifier the LLM uses.\n",
        "  - `func`: The Python function that will run when the tool is called.\n",
        "  - `description`: A natural language explanation of when and how to use the tool.\n",
        "- **Why wrap functions in a Tool?**  \n",
        "  The agent doesn't execute Python directly — it decides *which tool* to call, and LangChain handles running the underlying function.\n",
        "\n",
        "#### 2. **`initialize_agent`**\n",
        "- Function that creates an agent by combining:\n",
        "  - Your **tool list**.\n",
        "  - An **LLM**.\n",
        "  - An **agent type** (how the LLM decides on actions).\n",
        "- Returns an **agent executor** you can run.\n",
        "\n",
        "#### 3. **`AgentType.ZERO_SHOT_REACT_DESCRIPTION`**\n",
        "- A built-in LangChain agent type.\n",
        "- \"Zero-shot\" = The LLM decides what to do without seeing examples of previous runs.\n",
        "- \"React\" = Based on the **Reason + Act** framework:\n",
        "  1. **Reason** about the task.\n",
        "  2. Choose a **tool**.\n",
        "  3. Act by calling the tool.\n",
        "  4. Observe the result.\n",
        "  5. Repeat until finished.\n",
        "- \"Description\" = Uses your tool descriptions to decide which one to call.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example (Gemini-Only, Calculator Agent)\n"
      ],
      "metadata": {
        "id": "xpBd6SmuniPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "# Step 1: Create a simple tool (Python function)\n",
        "def multiply_numbers(query: str) -> str:\n",
        "    numbers = [int(x) for x in query.split() if x.isdigit()]\n",
        "    result = 1\n",
        "    for num in numbers:\n",
        "        result *= num\n",
        "    return str(result)\n",
        "\n",
        "# Wrap the tool for LangChain\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Multiplier\",\n",
        "        func=multiply_numbers,\n",
        "        description=\"Multiplies all numbers in a given string.\"\n",
        "    )\n",
        "]\n",
        "\n",
        "# Step 2: Initialize Gemini model\n",
        "model = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "\n",
        "# Step 3: Create the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=model,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# Step 4: Ask the agent to use the tool\n",
        "agent.run(\"Multiply 7 and 8\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "ImLwQNYomHMS",
        "outputId": "51fbfc76-8d8e-4d66-d3cf-49dbdec52c7b"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2405774310.py:26: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to multiply the numbers 7 and 8.  I can use the Multiplier tool for this.\n",
            "Action: Multiplier\n",
            "Action Input: \"7 8\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m56\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: 56\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'56'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 6\n",
        "\n",
        "**Goal:**  \n",
        "We will practice creating an agent that can dynamically use a custom Python tool to search through a list of movies.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Build the Tool**\n",
        "1. Create a Python function named `search_movies(query: str)` that:\n",
        "   - Searches a predefined Python list of movie titles (at least 10 titles).\n",
        "   - Returns all matches that contain the query term (case-insensitive).\n",
        "   - If no match is found, return `\"No results found.\"`.\n",
        "2. Wrap the function in a `Tool` object:\n",
        "   - `name`: `\"Movie Search Tool\"`\n",
        "   - `func`: Your `search_movies` function.\n",
        "   - `description`: `\"Searches for movies in a predefined list by matching the given keyword.\"`\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 2 — Create the Agent**\n",
        "1. Initialize `ChatGoogleGenerativeAI` with:\n",
        "   - `model=\"gemini-1.5-flash\"`\n",
        "   - `temperature=0` (for predictable output).\n",
        "2. Use `initialize_agent` to create the agent with:\n",
        "   - Your movie search tool inside the `tools` list.\n",
        "   - `AgentType.ZERO_SHOT_REACT_DESCRIPTION`.\n",
        "   - `verbose=True` to print the reasoning steps.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 3 — Test the Agent**\n",
        "1. Ask: `\"Find all movies that have the word 'Matrix' in them\"`.\n",
        "2. Ask: `\"List all movies starting with the letter I\"`.\n",
        "3. Ask: `\"Do we have any movies containing the word 'Star'?\"`.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 4 — Stretch Challenge (Optional)**\n",
        "1. Add a second tool called `count_movies`:\n",
        "   - Takes no arguments.\n",
        "   - Returns the total number of movies in the list.\n",
        "2. Update the agent to include both tools.\n",
        "3. Test with: `\"How many movies are in our collection?\"`.\n",
        "\n",
        "---\n",
        "\n",
        "> **Tip:**  \n",
        "> When designing tools, make the `description` very clear — the agent uses this text to decide when and how to call the tool.\n"
      ],
      "metadata": {
        "id": "3Paql1yipIx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lesson 6 — Agent with Custom Tools (Solution)\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "\n",
        "# Sample dataset\n",
        "MOVIES = [\n",
        "    \"The Matrix\",\n",
        "    \"The Matrix Reloaded\",\n",
        "    \"The Matrix Revolutions\",\n",
        "    \"Interstellar\",\n",
        "    \"Inception\",\n",
        "    \"Inside Out\",\n",
        "    \"Iron Man\",\n",
        "    \"The Imitation Game\",\n",
        "    \"Star Wars: A New Hope\",\n",
        "    \"Star Trek\",\n",
        "    \"Indiana Jones and the Last Crusade\",\n",
        "    \"Whiplash\",\n",
        "    \"Arrival\",\n",
        "    \"Inglourious Basterds\",\n",
        "]\n",
        "\n",
        "# Tool 1: substring search (case-insensitive)\n",
        "def search_movies(query: str) -> str:\n",
        "    q = query.strip().lower()\n",
        "    if not q:\n",
        "        return \"No results found.\"\n",
        "    results = [t for t in MOVIES if q in t.lower()]\n",
        "    return \"\\n\".join(results) if results else \"No results found.\"\n",
        "\n",
        "# Tool 2: prefix search (case-insensitive)\n",
        "def search_movies_by_prefix(prefix: str) -> str:\n",
        "    p = prefix.strip().lower()\n",
        "    if not p:\n",
        "        return \"No results found.\"\n",
        "    results = [t for t in MOVIES if t.lower().startswith(p)]\n",
        "    return \"\\n\".join(results) if results else \"No results found.\"\n",
        "\n",
        "# Tool 3 (stretch): count movies\n",
        "def count_movies(_: str = \"\") -> str:\n",
        "    return str(len(MOVIES))\n",
        "\n",
        "# Wrap tools for the agent\n",
        "tools = [\n",
        "    Tool(\n",
        "        name=\"Movie Search Tool\",\n",
        "        func=search_movies,\n",
        "        description=(\n",
        "            \"Searches a predefined list of movie titles and returns all titles containing the given keyword. \"\n",
        "            \"Use for general keyword searches like 'Matrix' or 'Star'.\"\n",
        "        ),\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Movie Prefix Tool\",\n",
        "        func=search_movies_by_prefix,\n",
        "        description=(\n",
        "            \"Returns all movie titles that start with the provided prefix (case-insensitive). \"\n",
        "            \"Use for requests like 'starting with the letter I'.\"\n",
        "        ),\n",
        "    ),\n",
        "    Tool(\n",
        "        name=\"Movie Count Tool\",\n",
        "        func=count_movies,\n",
        "        description=(\n",
        "            \"Returns the total number of movies in the collection. \"\n",
        "            \"Use when asked to count movies.\"\n",
        "        ),\n",
        "    ),\n",
        "]\n",
        "\n",
        "# Initialize Gemini model (temperature 0 for predictable tool use)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "\n",
        "# Create the agent\n",
        "agent = initialize_agent(\n",
        "    tools=tools,\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True,  # Set to False to reduce logs\n",
        ")\n",
        "\n",
        "# Tests\n",
        "print(\"\\n--- Query 1 ---\")\n",
        "print(agent.run(\"Find all movies that have the word 'Matrix' in them\"))\n",
        "\n",
        "print(\"\\n--- Query 2 ---\")\n",
        "print(agent.run(\"List all movies starting with the letter I\"))\n",
        "\n",
        "print(\"\\n--- Query 3 ---\")\n",
        "print(agent.run(\"Do we have any movies containing the word 'Star'?\"))\n",
        "\n",
        "print(\"\\n--- Stretch: Count ---\")\n",
        "print(agent.run(\"How many movies are in our collection?\"))\n",
        "\n",
        "print(\"\\n--- : Count ---\")\n",
        "print(agent.run(\"How many movies are in our collection?\"))\n",
        "\n",
        "\n",
        "# Negative tests\n",
        "print(\"\\n--- Negative: No Matches ---\")\n",
        "print(agent.run(\"Find all movies containing 'Batman'\"))\n",
        "\n",
        "print(\"\\n--- Negative: Empty Search Term ---\")\n",
        "print(agent.run(\"Find all movies containing ''\"))\n",
        "\n",
        "print(\"\\n--- Negative: Invalid Prefix ---\")\n",
        "print(agent.run(\"List all movies starting with 'ZZZ'\"))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b3J6JSdtoEdI",
        "outputId": "90535552-3b0f-4ef3-d16b-ca9084f83c44"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1548822414.py:76: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
            "  agent = initialize_agent(\n",
            "/tmp/ipython-input-1548822414.py:85: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  print(agent.run(\"Find all movies that have the word 'Matrix' in them\"))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Query 1 ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword \"Matrix\".  The Movie Search Tool is appropriate for this.\n",
            "Action: Movie Search Tool\n",
            "Action Input: Matrix\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe Matrix\n",
            "The Matrix Reloaded\n",
            "The Matrix Revolutions\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: The Matrix, The Matrix Reloaded, The Matrix Revolutions\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The Matrix, The Matrix Reloaded, The Matrix Revolutions\n",
            "\n",
            "--- Query 2 ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the Movie Prefix Tool to find all movies starting with 'I'.\n",
            "Action: Movie Prefix Tool\n",
            "Action Input: I\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mInterstellar\n",
            "Inception\n",
            "Inside Out\n",
            "Iron Man\n",
            "Indiana Jones and the Last Crusade\n",
            "Inglourious Basterds\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: Interstellar, Inception, Inside Out, Iron Man, Indiana Jones and the Last Crusade, Inglourious Basterds\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Interstellar, Inception, Inside Out, Iron Man, Indiana Jones and the Last Crusade, Inglourious Basterds\n",
            "\n",
            "--- Query 3 ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword 'Star'.\n",
            "Action: Movie Search Tool\n",
            "Action Input: Star\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mStar Wars: A New Hope\n",
            "Star Trek\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer.\n",
            "Final Answer: Yes, we have at least two movies containing the word 'Star': Star Wars: A New Hope and Star Trek.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Yes, we have at least two movies containing the word 'Star': Star Wars: A New Hope and Star Trek.\n",
            "\n",
            "--- Stretch: Count ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the Movie Count Tool to get the total number of movies.\n",
            "Action: Movie Count Tool\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m14\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: There are 14 movies in our collection.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "There are 14 movies in our collection.\n",
            "\n",
            "--- : Count ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the Movie Count Tool to get the total number of movies.\n",
            "Action: Movie Count Tool\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m14\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: There are 14 movies in our collection.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "There are 14 movies in our collection.\n",
            "\n",
            "--- Negative: No Matches ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword \"Batman\".  The Movie Search Tool is appropriate for this.\n",
            "Action: Movie Search Tool\n",
            "Action Input: Batman\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo results found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword \"Batman\".  The Movie Search Tool is appropriate for this.\n",
            "Action: Movie Search Tool\n",
            "Action Input: Batman\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo results found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword \"Batman\".  The Movie Search Tool is appropriate for this.\n",
            "Action: Movie Search Tool\n",
            "Action Input: Batman\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo results found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword \"Batman\".  The Movie Search Tool is appropriate for this.\n",
            "Action: Movie Search Tool\n",
            "Action Input: Batman\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo results found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to search for movies containing the keyword \"Batman\".  The Movie Search Tool is appropriate for this.  Since there are no Batman movies in the database, I will state that.\n",
            "Thought: I now know the final answer\n",
            "Final Answer: There are no movies containing 'Batman' in the database.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "There are no movies containing 'Batman' in the database.\n",
            "\n",
            "--- Negative: Empty Search Term ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the Movie Search Tool to find all movies containing an empty string.  This should return all movies.\n",
            "Action: Movie Search Tool\n",
            "Action Input: ''\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mNo results found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mQuestion: Find all movies containing ''\n",
            "Thought: I need to use the Movie Search Tool to find all movies containing an empty string.  This should return all movies.  However, the observation shows no results.  This likely means the search tool doesn't handle empty strings correctly. I'll try a different approach.  I can get the total number of movies using the Movie Count Tool.\n",
            "Action: Movie Count Tool\n",
            "Action Input: \u001b[0m\n",
            "Observation: \u001b[38;5;200m\u001b[1;3m14\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer.  The Movie Count Tool indicates there are 14 movies in total.\n",
            "Final Answer: 14\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "14\n",
            "\n",
            "--- Negative: Invalid Prefix ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to use the Movie Prefix Tool to find all movies starting with 'ZZZ'.\n",
            "Action: Movie Prefix Tool\n",
            "Action Input: ZZZ\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mNo results found.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now know the final answer\n",
            "Final Answer: There are no movies starting with 'ZZZ'.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "There are no movies starting with 'ZZZ'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 7 — Building a Custom Tool <a name=\"lesson-7\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to create **custom tools** the agent can call at runtime. We will:\n",
        "- Wrap a Python function as a **Tool** (simple arguments).\n",
        "- Define a **Structured Tool** with a schema (validated, multi-argument calls).\n",
        "- Add both tools to an agent and see them used through the agent loop.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### What is a Tool?\n",
        "A **Tool** is a callable capability that the agent can invoke to do non‑LLM work (e.g., search, math, DB lookups). Tools are wrappers around Python functions with **name** and **description** so the LLM knows when to call them.\n",
        "\n",
        "- **Why tools?** Agents can’t access data or perform actions by themselves; tools are how they interact with the outside world.\n",
        "\n",
        "#### `Tool` vs `StructuredTool`\n",
        "- **`Tool`** (simple): Wraps a Python function that takes a **single string** input and returns a string. Good for quick utilities and simple prompts like “search for X”.\n",
        "- **`StructuredTool` / `@tool(..., args_schema=...)`**: Adds a **Pydantic schema** for multiple/typed arguments with validation. The agent can pass structured kwargs reliably.\n",
        "\n",
        "## 🛠 Tool vs Structured Tool in LangChain\n",
        "\n",
        "### 1. **Tool**\n",
        "- **Definition:** A wrapper around a **single-argument Python function** that the agent can call.\n",
        "- **Input/Output:** Takes one string as input and returns one string as output.\n",
        "- **Use Case:** Quick, simple actions where all necessary input can be expressed in one string.\n",
        "- **Example:**\n",
        "\n",
        "```python\n",
        "from langchain.agents import Tool\n",
        "\n",
        "def keyword_search(query: str) -> str:\n",
        "    return f\"Searching for: {query}\"\n",
        "\n",
        "search_tool = Tool(\n",
        "    name=\"Keyword Search\",\n",
        "    func=keyword_search,\n",
        "    description=\"Search for items that contain a given keyword.\"\n",
        ")\n",
        "```\n",
        "\n",
        "\n",
        "### 2. **Structured Tool **\n",
        "- **Definition:** A wrapper around a Python function that can take multiple typed arguments, validated with a Pydantic schema.\n",
        "\n",
        "- **Input/Output:**  Accepts structured, typed inputs (e.g., integers, floats, strings, booleans), not just one string.\n",
        "\n",
        "- **Use Case:** When you want automatic input validation so the agent doesn’t send wrong types or missing fields.\n",
        "\n",
        "- **Example:**\n",
        "\n",
        "```python\n",
        "from langchain.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Define the schema\n",
        "class FilterArgs(BaseModel):\n",
        "    prefix: str = Field(..., description=\"Title must start with this prefix.\")\n",
        "    min_length: int = Field(0, description=\"Minimum title length.\")\n",
        "\n",
        "# Create the structured tool\n",
        "@tool(\"filtered_search\", args_schema=FilterArgs)\n",
        "def filtered_search(prefix: str, min_length: int = 0) -> str:\n",
        "    return f\"Filtering titles starting with {prefix}, min length {min_length}\"\n",
        "```\n",
        "---\n",
        "\n",
        "\n",
        "### 📊 Comparison Table\n",
        "\n",
        "| Feature               | Tool                           | Structured Tool                        |\n",
        "|-----------------------|--------------------------------|-----------------------------------------|\n",
        "| Input type            | Single `str`                   | Multiple typed arguments                |\n",
        "| Validation            | ❌ None                        | ✅ Pydantic validation                   |\n",
        "| Example               | Keyword search                 | Filtered search with prefix & min length|\n",
        "| Agent compatibility   | Works with most classic agents | Needs tool-calling or OpenAI-style agents|\n",
        "\n",
        "---\n",
        "\n",
        "### 3. **What is a Pydantic schema?**\n",
        "\n",
        "Pydantic is a Python library for data validation and type enforcement.\n",
        "\n",
        "- A schema is a Python class (subclass of BaseModel) that:\n",
        "\n",
        "- Lists all the inputs (fields) your function needs.\n",
        "\n",
        "- Specifies the type of each field (str, int, float, etc.).\n",
        "\n",
        "- Adds optional descriptions (Field(description=\"...\")).\n",
        "\n",
        "Benefits in LangChain tools:\n",
        "\n",
        "- The LLM sees the schema and knows exactly what inputs to provide.\n",
        "\n",
        "- Prevents malformed tool calls (e.g., sending a string where an integer is required).\n",
        "---\n",
        "\n",
        "#### `initialize_agent`\n",
        "Combines:\n",
        "- Your **tools** list\n",
        "- The **LLM**\n",
        "- An **agent type** (the decision framework, e.g., `ZERO_SHOT_REACT_DESCRIPTION`)\n",
        "and returns an **agent executor**. Calling `.run(prompt)` lets the LLM select tools, call them, observe results, and iterate.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔧 New APIs Explained\n",
        "\n",
        "- **`Tool(name, func, description)`**\n",
        "  - `name`: Short identifier the LLM will mention when choosing a tool.\n",
        "  - `func`: Python function to execute.\n",
        "  - `description`: Natural language guide that the LLM reads to decide when to use it.\n",
        "- **`@tool(args_schema=...)` (decorator)**\n",
        "  - Wraps a function as a **structured tool**.\n",
        "  - `args_schema`: a Pydantic `BaseModel` describing parameters, types, and descriptions.\n",
        "- **`AgentType.ZERO_SHOT_REACT_DESCRIPTION`**\n",
        "  - Zero-shot: no few-shot examples; agent decides steps from scratch.\n",
        "  - ReAct: **Reason → Act → Observe → Repeat**.\n",
        "  - Description: Chooses tools based on your tool **descriptions**.\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "PBMF0okKsQM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Example: Tool vs Structured Tool in LangChain (Gemini)\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.agents import initialize_agent, Tool, AgentType\n",
        "from langchain.tools import tool\n",
        "from pydantic import BaseModel, Field\n",
        "\n",
        "# Sample dataset\n",
        "MOVIES = [\"The Matrix\", \"Interstellar\", \"Inception\", \"Inside Out\", \"Iron Man\"]\n",
        "\n",
        "# ------------------------------\n",
        "# 1) Tool — Single String Input\n",
        "# ------------------------------\n",
        "def keyword_search(query: str) -> str:\n",
        "    \"\"\"Returns all movies containing the keyword (case-insensitive).\"\"\"\n",
        "    q = query.strip().lower()\n",
        "    hits = [m for m in MOVIES if q in m.lower()]\n",
        "    return \"\\n\".join(hits) if hits else \"No results found.\"\n",
        "\n",
        "simple_tool = Tool(\n",
        "    name=\"Movie Keyword Search\",\n",
        "    func=keyword_search,\n",
        "    description=\"Search for movies containing the given keyword (string).\"\n",
        ")\n",
        "\n",
        "# ------------------------------\n",
        "# 2) Structured Tool — Multiple Typed Arguments\n",
        "# ------------------------------\n",
        "class FilterArgs(BaseModel):\n",
        "    prefix: str = Field(..., description=\"Title must start with this prefix (case-insensitive).\")\n",
        "    min_length: int = Field(0, description=\"Minimum title length in characters.\")\n",
        "\n",
        "@tool(\"filtered_movie_search\", args_schema=FilterArgs)\n",
        "def filtered_movie_search(prefix: str, min_length: int = 0) -> str:\n",
        "    \"\"\"Returns movies starting with a given prefix and meeting min length.\"\"\"\n",
        "    hits = [m for m in MOVIES if m.lower().startswith(prefix.lower()) and len(m) >= min_length]\n",
        "    return \"\\n\".join(hits) if hits else \"No results found.\"\n",
        "\n",
        "# ------------------------------\n",
        "# 3) Run Tool directly\n",
        "# ------------------------------\n",
        "print(\"\\n--- Direct Tool Test ---\")\n",
        "print(\"Keyword Search('Matrix') →\")\n",
        "print(simple_tool.run(\"Matrix\"))\n",
        "\n",
        "# ------------------------------\n",
        "# 4) Run Structured Tool directly\n",
        "# ------------------------------\n",
        "print(\"\\n--- Direct Structured Tool Test ---\")\n",
        "print(\"Filtered Search(prefix='In', min_length=10) →\")\n",
        "print(filtered_movie_search.run({\"prefix\": \"In\", \"min_length\": 10}))\n",
        "\n",
        "# ------------------------------\n",
        "# 5) Using the Tool inside a classic agent\n",
        "# ------------------------------\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "\n",
        "# Only add simple_tool here — classic ZERO_SHOT agent can't use multi-input tools\n",
        "agent_simple = initialize_agent(\n",
        "    tools=[simple_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    max_iterations = 3,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "print(\"\\n--- Agent using simple Tool ---\")\n",
        "print(agent_simple.run(\"Find movies with the word Matrix\"))\n",
        "\n",
        "# ------------------------------\n",
        "# 6) Structured tools require a tool-calling agent (not classic ZERO_SHOT)\n",
        "# ------------------------------\n",
        "from langchain.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
        "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
        "\n",
        "prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a helpful assistant. Use tools when needed.\"),\n",
        "    (\"human\", \"{input}\"),\n",
        "    MessagesPlaceholder(\"agent_scratchpad\")\n",
        "])\n",
        "\n",
        "tools_for_structured = [filtered_movie_search]\n",
        "agent_structured = create_tool_calling_agent(llm=llm, tools=tools_for_structured, prompt=prompt)\n",
        "executor = AgentExecutor(agent=agent_structured, tools=tools_for_structured, verbose=True)\n",
        "\n",
        "print(\"\\n--- Agent using Structured Tool ---\")\n",
        "print(executor.invoke({\"input\": \"List movies starting with 'In' that are at least 10 characters long\"})[\"output\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uac0y0KgsQlZ",
        "outputId": "db9e8540-1330-4d3e-be53-ab04b12592ab"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Direct Tool Test ---\n",
            "Keyword Search('Matrix') →\n",
            "The Matrix\n",
            "\n",
            "--- Direct Structured Tool Test ---\n",
            "Filtered Search(prefix='In', min_length=10) →\n",
            "Interstellar\n",
            "Inside Out\n",
            "\n",
            "--- Agent using simple Tool ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to search for movies that contain the keyword \"Matrix\".  I can use the Movie Keyword Search tool for this.\n",
            "Action: Movie Keyword Search\n",
            "Action Input: Matrix\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe Matrix\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to search for movies that contain the keyword \"Matrix\".  I can use the Movie Keyword Search tool for this.\n",
            "Action: Movie Keyword Search\n",
            "Action Input: Matrix\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe Matrix\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I need to search for movies that contain the keyword \"Matrix\".  I can use the Movie Keyword Search tool for this.\n",
            "Action: Movie Keyword Search\n",
            "Action Input: Matrix\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mThe Matrix\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3m\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "Agent stopped due to iteration limit or time limit.\n",
            "\n",
            "--- Agent using Structured Tool ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `filtered_movie_search` with `{'min_length': 10.0, 'prefix': 'In'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mInterstellar\n",
            "Inside Out\u001b[0m\u001b[32;1m\u001b[1;3mThe movies are Interstellar and Inside Out.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "The movies are Interstellar and Inside Out.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Agent using Structured Tool Negative test ---\")\n",
        "print(executor.invoke({\"input\": \"List movies that start with The and is 100 characters long \"})[\"output\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FcYszrj0PKC",
        "outputId": "65710c16-92e6-4292-b7de-2ce5750d939a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Agent using Structured Tool Negative test ---\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3m\n",
            "Invoking: `filtered_movie_search` with `{'min_length': 100.0, 'prefix': 'The'}`\n",
            "\n",
            "\n",
            "\u001b[0m\u001b[36;1m\u001b[1;3mNo results found.\u001b[0m\u001b[32;1m\u001b[1;3mThere are no movies found that start with \"The\" and have a length of 100 characters.\n",
            "\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "There are no movies found that start with \"The\" and have a length of 100 characters.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 8 — Loading and Splitting Documents <a name=\"lesson-8\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to:\n",
        "1. **Load documents** into LangChain from common sources (text, PDFs, web pages).\n",
        "2. **Split documents** into smaller chunks so LLMs can process them efficiently.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### **What is a Document in LangChain?**\n",
        "- A `Document` in LangChain is an object with:\n",
        "  - `.page_content`: The text of the document (string).\n",
        "  - `.metadata`: Extra info about the document (e.g., source, page number).\n",
        "- LLMs have context length limits — they can’t process entire books or long PDFs in one go.\n",
        "\n",
        "#### **Why Split Documents?**\n",
        "- Splitting long text into **chunks**:\n",
        "  - Prevents exceeding token limits.\n",
        "  - Makes retrieval more relevant (you fetch only the most relevant chunks).\n",
        "  - Improves RAG performance and speed.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 New Classes\n",
        "\n",
        "#### 1. **Document Loaders**\n",
        "LangChain provides many loaders for different formats:\n",
        "- `TextLoader` — Loads plain text files.\n",
        "- `PyPDFLoader` — Loads PDFs, one page per document.\n",
        "- `UnstructuredFileLoader` — Handles multiple formats (PDF, DOCX, etc.).\n",
        "- `WebBaseLoader` — Loads text from a web URL.\n",
        "\n",
        "#### 2. **Text Splitters**\n",
        "- `CharacterTextSplitter` — Splits by character count.\n",
        "- `RecursiveCharacterTextSplitter` — Splits by characters, but tries to keep logical boundaries (paragraphs, sentences).\n",
        "- **Parameters:**\n",
        "  - `chunk_size`: Max characters/tokens per chunk.\n",
        "  - `chunk_overlap`: How much content overlaps between chunks (helps preserve context).\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "e0wvAF1Y6DeA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Step 1: Load document\n",
        "loader = TextLoader(\"sample.txt\", encoding=\"utf-8\")  # Replace with your file\n",
        "docs = loader.load()\n",
        "print(f\"Loaded {len(docs)} document(s).\")\n",
        "print(\"Sample content:\", docs[0].page_content[:200])\n",
        "\n",
        "# Step 2: Split into chunks\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=50\n",
        ")\n",
        "chunks = splitter.split_documents(docs)\n",
        "print(f\"Split into {len(chunks)} chunks.\")\n",
        "print(\"First chunk:\", chunks[0].page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2WyXNHtm6EDN",
        "outputId": "695ab89c-8f59-4997-dcdd-03edac512f8f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 1 document(s).\n",
            "Sample content: LangChain is a framework for developing applications powered by large language models (LLMs). It provides a standard interface for chains, modules for various tasks, and integration with many LLM prov\n",
            "Split into 8 chunks.\n",
            "First chunk: LangChain is a framework for developing applications powered by large language models (LLMs). It provides a standard interface for chains, modules for various tasks, and integration with many LLM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 8\n",
        "\n",
        "**Goal:**  \n",
        "We will practice loading text from files and other sources, then splitting it into smaller chunks for LLM processing.\n",
        "\n",
        "\n",
        "\n",
        "**Content**\n",
        "---\n",
        "LangChain is a framework for developing applications powered by large language models (LLMs). It provides a standard interface for chains, modules for various tasks, and integration with many LLM providers.\n",
        "\n",
        "One of the core challenges when working with LLMs is managing the limited context length. If you try to send too much text at once, the model may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.\n",
        "\n",
        "Splitting text into chunks improves retrieval quality when you search for relevant information. For example, in a Retrieval-Augmented Generation (RAG) setup, a user's query is matched against these smaller chunks, and only the most relevant ones are sent to the LLM. This reduces the token cost and improves accuracy.\n",
        "\n",
        "LangChain supports a variety of document loaders for different formats, including plain text, PDFs, HTML, and Word documents. It also offers multiple text splitting strategies, such as character-based and recursive splitting, which respect natural boundaries like sentences and paragraphs.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Load a Local Text File**\n",
        "1. Save the provided sample content into a file named `sample.txt`.\n",
        "2. Use `TextLoader` to load the file.\n",
        "3. Print:\n",
        "   - Number of documents loaded.\n",
        "   - First 150 characters of the first document.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 2 — Split into Chunks**\n",
        "1. Use `RecursiveCharacterTextSplitter` with:\n",
        "   - `chunk_size=150`\n",
        "   - `chunk_overlap=30`\n",
        "2. Print:\n",
        "   - Total number of chunks.\n",
        "   - The first 2 chunks’ text.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 3 — Load a PDF**\n",
        "1. Install:\n",
        "   ```bash\n",
        "   pip install pypdf\n",
        "   ```\n",
        "2. Use PyPDFLoader to load any PDF file you have.\n",
        "\n",
        "3. Split the loaded content into chunks (choose your own chunk_size and chunk_overlap).\n",
        "\n",
        "4. Print:\n",
        "  * The total number of chunks.\n",
        "  * The metadata and first 200 characters of the first chunk.\n",
        "\n",
        "---\n",
        "#### **Part 4 — Load from a URL (Stretch)**\n",
        "1. Install the required library for web scraping:\n",
        "\n",
        "```bash\n",
        "pip install beautifulsoup4\n",
        "```\n",
        "\n",
        "2. Use WebBaseLoader to load content from any public web page.\n",
        "\n",
        "3. Split it into chunks using RecursiveCharacterTextSplitter.\n",
        "\n",
        "4. Print:\n",
        "  * The total number of chunks.\n",
        "  * The text of the first chunk."
      ],
      "metadata": {
        "id": "-n6e92JU71M9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 1 — Load a Local Text File\n",
        "\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "\n",
        "# Step 1: Create loader for sample.txt\n",
        "loader = TextLoader(\"sample.txt\", encoding=\"utf-8\")\n",
        "\n",
        "# Step 2: Load document(s)\n",
        "docs = loader.load()\n",
        "\n",
        "# Step 3: Print results\n",
        "print(f\"Total documents loaded: {len(docs)}\")\n",
        "if docs:\n",
        "    print(\"\\nFirst 200 characters of first document:\\n\")\n",
        "    print(docs[0].page_content[:200])\n",
        "else:\n",
        "    print(\"No documents found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "zNnNqRC272bs",
        "outputId": "cc03c1c2-61a5-40c1-ad85-4bac84fc49a3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'langchain_community'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-426671991.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Part 1 — Load a Local Text File\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlangchain_community\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_loaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Step 1: Create loader for sample.txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_community'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 2 — Split into Chunks\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Step 1: Create splitter\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=150,      # max characters per chunk\n",
        "    chunk_overlap=30     # overlap between chunks to preserve context\n",
        ")\n",
        "\n",
        "# Step 2: Split the loaded docs into smaller chunks\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# Step 3: Print results\n",
        "print(f\"Total chunks created: {len(chunks)}\\n\")\n",
        "\n",
        "# Preview the first two chunks\n",
        "for i, chunk in enumerate(chunks[:2]):\n",
        "    print(f\"--- Chunk {i+1} ---\")\n",
        "    print(chunk.page_content)\n",
        "    print()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AD9Vb98A-UaT",
        "outputId": "a77e9890-b82b-42dc-f5aa-e40fafdf810f"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total chunks created: 11\n",
            "\n",
            "--- Chunk 1 ---\n",
            "LangChain is a framework for developing applications powered by large language models (LLMs). It provides a standard interface for chains, modules for\n",
            "\n",
            "--- Chunk 2 ---\n",
            "for chains, modules for various tasks, and integration with many LLM providers.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_DVcb9YBfu1",
        "outputId": "22afb9f7-bcf6-4237-c100-ded7227773d8"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-5.9.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Downloading pypdf-5.9.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/313.2 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pypdf\n",
            "Successfully installed pypdf-5.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 3 — Load a PDF and Split\n",
        "\n",
        "\n",
        "# 1) Load PDF (replace with your file path, e.g., \"documents/report.pdf\")\n",
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "pdf_path = \"my_doc.pdf\"  # <-- change this to your actual PDF\n",
        "loader = PyPDFLoader(pdf_path)\n",
        "\n",
        "docs_pdf = loader.load()\n",
        "print(f\"Total PDF pages loaded as documents: {len(docs_pdf)}\")\n",
        "if not docs_pdf:\n",
        "    raise FileNotFoundError(f\"No pages loaded. Check the path: {pdf_path}\")\n",
        "\n",
        "# Show first page metadata and preview\n",
        "print(\"\\n--- First page metadata ---\")\n",
        "print(docs_pdf[0].metadata)\n",
        "print(\"\\n--- First 200 chars of first page ---\")\n",
        "print(docs_pdf[0].page_content[:200])\n",
        "\n",
        "# 2) Split into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n",
        "chunks_pdf = splitter.split_documents(docs_pdf)\n",
        "\n",
        "print(f\"\\nTotal PDF chunks: {len(chunks_pdf)}\")\n",
        "print(\"\\n--- First chunk metadata ---\")\n",
        "print(chunks_pdf[0].metadata)\n",
        "print(\"\\n--- First 200 chars of first chunk ---\")\n",
        "print(chunks_pdf[0].page_content[:200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NrObtYES-cFu",
        "outputId": "b24a4543-1adb-46c5-d417-8f5bd73db8a1"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total PDF pages loaded as documents: 4\n",
            "\n",
            "--- First page metadata ---\n",
            "{'producer': 'Acrobat Distiller 6.0 (Windows)', 'creator': 'Illustrator', 'creationdate': '2006-06-06T16:59:12+10:00', 'subject': 'test', 'author': 'Anne', 'moddate': '2006-06-06T16:59:29+10:00', 'title': 'test', 'source': 'my_doc.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "--- First 200 chars of first page ---\n",
            "ANOTHER LOOK AT FORECAST -ACCURACY METRICS\n",
            "FOR INTERMITTENT DEMAND\n",
            "by Rob J. Hyndman\n",
            "Preview: Some traditional measurements of forecast accuracy are unsuitable for intermittent-demand data\n",
            "because the\n",
            "\n",
            "Total PDF chunks: 72\n",
            "\n",
            "--- First chunk metadata ---\n",
            "{'producer': 'Acrobat Distiller 6.0 (Windows)', 'creator': 'Illustrator', 'creationdate': '2006-06-06T16:59:12+10:00', 'subject': 'test', 'author': 'Anne', 'moddate': '2006-06-06T16:59:29+10:00', 'title': 'test', 'source': 'my_doc.pdf', 'total_pages': 4, 'page': 0, 'page_label': '1'}\n",
            "\n",
            "--- First 200 chars of first chunk ---\n",
            "ANOTHER LOOK AT FORECAST -ACCURACY METRICS\n",
            "FOR INTERMITTENT DEMAND\n",
            "by Rob J. Hyndman\n",
            "Preview: Some traditional measurements of forecast accuracy are unsuitable for intermittent-demand data\n",
            "because the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Part 4 — Load from a URL and Split\n",
        "\n",
        "# 1) Install dependency (run once per environment)\n",
        "import bs4  # noqa\n",
        "\n",
        "# 2) Load web page content\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://python.langchain.com/docs/introduction/\"  # <-- replace with a public page you want to test\n",
        "loader = WebBaseLoader(url)\n",
        "\n",
        "docs_web = loader.load()\n",
        "print(f\"Total web documents loaded: {len(docs_web)}\")\n",
        "if not docs_web:\n",
        "    raise RuntimeError(f\"No content loaded from URL: {url}\")\n",
        "\n",
        "# Show basic metadata and a short preview\n",
        "print(\"\\n--- First doc metadata ---\")\n",
        "print(docs_web[0].metadata)\n",
        "print(\"\\n--- First 300 chars of first doc ---\")\n",
        "print(docs_web[0].page_content[:300])\n",
        "\n",
        "# 3) Split into chunks\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=300, chunk_overlap=60)\n",
        "chunks_web = splitter.split_documents(docs_web)\n",
        "\n",
        "print(f\"\\nTotal web chunks: {len(chunks_web)}\")\n",
        "print(\"\\n--- First chunk preview ---\")\n",
        "print(chunks_web[0].page_content[:300])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYmY_cNkAwxD",
        "outputId": "8127937d-1f20-4a8f-90ce-01600db98455"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total web documents loaded: 1\n",
            "\n",
            "--- First doc metadata ---\n",
            "{'source': 'https://python.langchain.com/docs/introduction/', 'title': 'Introduction | \\uf8ffü¶úÔ∏è\\uf8ffüîó LangChain', 'description': 'LangChain is a framework for developing applications powered by large language models (LLMs).', 'language': 'en'}\n",
            "\n",
            "--- First 300 chars of first doc ---\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Introduction | ü¶úÔ∏èüîó LangChain\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Skip to main contentOur Building Ambient Agents with LangGraph course is now available on LangChain Academy!IntegrationsAPI ReferenceMoreContributingPeopleError referenceLangSmithLangGraphLangChain HubLangChain JS/TSv0.3v0.3v0.2v0.1üí¨SearchIntroduc\n",
            "\n",
            "Total web chunks: 55\n",
            "\n",
            "--- First chunk preview ---\n",
            "Introduction | ü¶úÔ∏èüîó LangChain\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 9 — Embeddings & Vector Stores (FAISS) <a name=\"lesson-9\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We’ll learn how to convert text chunks into **numeric embeddings**, store them in a **vector database (FAISS)**, and perform **similarity search** to power retrieval for RAG.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### What are Embeddings?\n",
        "Embeddings are **dense numeric vectors** that represent text such that **semantic similarity ≈ vector proximity**. If two texts are similar, their vectors are close in vector space.\n",
        "\n",
        "#### Why do we need them?\n",
        "LLMs can’t “search” long corpora by themselves. We:\n",
        "1) **Embed** our documents into vectors  \n",
        "2) **Index** them in a vector store  \n",
        "3) **Retrieve** the top‑k most similar chunks for a query  \n",
        "4) Feed those chunks to the LLM as **context** (RAG)\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 New Classes / Functions\n",
        "\n",
        "- **`GoogleGenerativeAIEmbeddings`**  \n",
        "  Creates embeddings using Gemini’s embedding model.  \n",
        "  - `model`: embedding model name (e.g., `\"models/text-embedding-004\"`).  \n",
        "  - `.embed_documents(list[str])` returns a list of vectors.  \n",
        "  - `.embed_query(str)` returns a single vector for the query.\n",
        "\n",
        "- **`FAISS` (Vector Store)**  \n",
        "  An in‑memory, fast, ANN index for vectors.  \n",
        "  - `FAISS.from_documents(docs, embeddings)` builds an index from `Document` chunks.  \n",
        "  - `.similarity_search(query, k=4)` returns the top‑k most similar chunks.  \n",
        "  - `.as_retriever(search_kwargs={\"k\": 4})` produces a **retriever** interface for use in chains.\n",
        "\n",
        "- **`k` (top‑k)**  \n",
        "  The number of nearest chunks to return for each search. Typical values: 3–8.\n",
        "\n",
        "- **Similarity vs. Relevance**  \n",
        "  Vector similarity is semantic; it’s a strong proxy for relevance but not perfect. We’ll later add reranking/filters.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal, Runnable Example (uses chunks from Lesson 8)\n",
        "\n",
        "**Assumption:** You ran Lesson 8 and have `chunks` (list of `Document`) ready. If not, quickly load and split `sample.txt` again."
      ],
      "metadata": {
        "id": "xQgL46_0FCKM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        " !pip install faiss-cpu\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "70q1i9UK5q1O",
        "outputId": "71267ef0-2506-4e25-9184-e5d1ebd0fb07"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (25.0)\n",
            "Downloading faiss_cpu-1.11.0.post1-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu\n",
            "Successfully installed faiss-cpu-1.11.0.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "# Step 1: Initialize embeddings (Gemini)\n",
        "emb = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "\n",
        "# Step 2: Build the FAISS vector store from document chunks\n",
        "vectorstore = FAISS.from_documents(chunks, emb)\n",
        "\n",
        "# Step 3: Similarity search\n",
        "query = \"Why do we split documents into chunks for RAG?\"\n",
        "results = vectorstore.similarity_search(query, k=3)\n",
        "\n",
        "print(f\"Top {len(results)} results:\")\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(doc.page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKH9FwPwFCtY",
        "outputId": "eb35c223-aba3-4f9f-ac40-1d8a3da67c1f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 3 results:\n",
            "\n",
            "--- Result 1 ---\n",
            "Splitting text into chunks improves retrieval quality when you search for relevant information. For example, in a Retrieval-Augmented Generation (RAG) setup, a user's query is matched against these\n",
            "\n",
            "--- Result 2 ---\n",
            "may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.\n",
            "\n",
            "--- Result 3 ---\n",
            "multiple text splitting strategies, such as character-based and recursive splitting, which respect natural boundaries like sentences and paragraphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 9: Embeddings & FAISS Vector Store\n",
        "\n",
        "**Goal:**  \n",
        "We will convert document chunks into embeddings, store them in a FAISS index, and perform similarity searches to retrieve the most relevant chunks for a given query.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 1 — Build the Index**\n",
        "1. Ensure you have your document chunks from Lesson 8 (variable: `chunks`).\n",
        "2. Initialize the embeddings object:\n",
        "   ```python\n",
        "   from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "   emb = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "  ```\n",
        "3. Build the FAISS index:\n",
        "\n",
        "   ```python\n",
        "from langchain_community.vectorstores import FAISS\n",
        "vectorstore = FAISS.from_documents(chunks, emb)\n",
        "  ```\n",
        "\n",
        "4. Print the number of documents stored:\n",
        "  ```python\n",
        "  print(\"Documents in index:\", len(vectorstore.docstore._dict))\n",
        "  ```\n",
        "\n",
        "---\n",
        "#### **Part 2 — Run Similarity Searches**\n",
        "1. Create three different queries related to your document content (e.g., \"What is LangChain?\", \"Why split documents into chunks?\", \"What are text splitting strategies?\").\n",
        "\n",
        "2. For each query, run:\n",
        "\n",
        "``` python\n",
        "results = vectorstore.similarity_search(query, k=3)\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(doc.page_content)\n",
        "\n",
        "```\n",
        "3. Check if the retrieved chunks are on-topic and relevant.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Part 3 — Create and Use a Retriever**\n",
        "\n",
        "1. Create a retriever:\n",
        "\n",
        "```python\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "```\n",
        "\n",
        "2. Use it to get documents:\n",
        "\n",
        "\n",
        "```python\n",
        "docs = retriever.get_relevant_documents(\"Your query here\")\n",
        "```\n",
        "\n",
        "3. Compare outputs with `similarity_search`\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "CfuxogSO7MRx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practice  Code below:"
      ],
      "metadata": {
        "id": "WX6FR5MX-jaC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chunks"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rKNv3m8FStv",
        "outputId": "7c9de5ff-5ec7-43f9-a47b-013fce768447"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(metadata={'source': 'sample.txt'}, page_content='LangChain is a framework for developing applications powered by large language models (LLMs). It provides a standard interface for chains, modules for various tasks, and integration with many LLM'),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content='for various tasks, and integration with many LLM providers.'),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content='One of the core challenges when working with LLMs is managing the limited context length. If you try to send too much text at once, the model may fail to process it or lose important details.'),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content='may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.'),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content=\"Splitting text into chunks improves retrieval quality when you search for relevant information. For example, in a Retrieval-Augmented Generation (RAG) setup, a user's query is matched against these\"),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content=\"setup, a user's query is matched against these smaller chunks, and only the most relevant ones are sent to the LLM. This reduces the token cost and improves accuracy.\"),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content='LangChain supports a variety of document loaders for different formats, including plain text, PDFs, HTML, and Word documents. It also offers multiple text splitting strategies, such as'),\n",
              " Document(metadata={'source': 'sample.txt'}, page_content='multiple text splitting strategies, such as character-based and recursive splitting, which respect natural boundaries like sentences and paragraphs.')]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "emb = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")"
      ],
      "metadata": {
        "id": "6OYm-WYy828D"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.vectorstores import FAISS\n",
        "vectorstore = FAISS.from_documents(chunks, emb)"
      ],
      "metadata": {
        "id": "nrQ9yuTK9CRV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Documents in index:\", len(vectorstore.docstore._dict))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zKgmoxUr9GB1",
        "outputId": "cb022449-e40b-4042-eb0a-01b9772268c0"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Documents in index: 8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What is LangChain?'\n",
        "results = vectorstore.similarity_search(query, k=3)\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zTazWfof9Hru",
        "outputId": "89efde0a-f1c2-477a-945d-909eab859d4e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "LangChain is a framework for developing applications powered by large language models (LLMs). It provides a standard interface for chains, modules for various tasks, and integration with many LLM\n",
            "\n",
            "--- Result 2 ---\n",
            "may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.\n",
            "\n",
            "--- Result 3 ---\n",
            "LangChain supports a variety of document loaders for different formats, including plain text, PDFs, HTML, and Word documents. It also offers multiple text splitting strategies, such as\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'Why split documents into chunks'\n",
        "results = vectorstore.similarity_search(query, k=3)\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QOwcCC419dmm",
        "outputId": "dba13ce9-0722-4a51-95c6-58035b0a74dc"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.\n",
            "\n",
            "--- Result 2 ---\n",
            "Splitting text into chunks improves retrieval quality when you search for relevant information. For example, in a Retrieval-Augmented Generation (RAG) setup, a user's query is matched against these\n",
            "\n",
            "--- Result 3 ---\n",
            "multiple text splitting strategies, such as character-based and recursive splitting, which respect natural boundaries like sentences and paragraphs.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = 'What are text splitting strategies?'\n",
        "results = vectorstore.similarity_search(query, k=3)\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Oe2yL6l9jFC",
        "outputId": "da934f48-8ad5-4062-821c-8dd0cbc24ea2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "multiple text splitting strategies, such as character-based and recursive splitting, which respect natural boundaries like sentences and paragraphs.\n",
            "\n",
            "--- Result 2 ---\n",
            "Splitting text into chunks improves retrieval quality when you search for relevant information. For example, in a Retrieval-Augmented Generation (RAG) setup, a user's query is matched against these\n",
            "\n",
            "--- Result 3 ---\n",
            "may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "docs = retriever.get_relevant_documents(\"What are text splitting strategies?\")\n",
        "for i, doc in enumerate(results, 1):\n",
        "    print(f\"\\n--- Result {i} ---\")\n",
        "    print(doc.page_content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cqXuZY29qDK",
        "outputId": "e8fb831a-9f7e-419e-c7fc-3a2d3525962d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 ---\n",
            "multiple text splitting strategies, such as character-based and recursive splitting, which respect natural boundaries like sentences and paragraphs.\n",
            "\n",
            "--- Result 2 ---\n",
            "Splitting text into chunks improves retrieval quality when you search for relevant information. For example, in a Retrieval-Augmented Generation (RAG) setup, a user's query is matched against these\n",
            "\n",
            "--- Result 3 ---\n",
            "may fail to process it or lose important details. LangChain addresses this by allowing you to split documents into smaller, overlapping chunks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmMgao6V96Ov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 10 — Retrieval-Augmented Generation (RAG) Chain <a name=\"lesson-10\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We will connect our FAISS retriever to a Gemini model so that:\n",
        "1. The user asks a question.\n",
        "2. Relevant document chunks are retrieved from the vector store.\n",
        "3. The chunks are fed into the LLM prompt so answers are grounded in the source material.\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### What is RAG?\n",
        "- **Retrieval-Augmented Generation** is an approach where the LLM is given **retrieved context** before generating an answer.\n",
        "- This helps:\n",
        "  - Reduce hallucinations (model making up facts)\n",
        "  - Improve accuracy on domain-specific questions\n",
        "  - Keep answers grounded in your dataset\n",
        "\n",
        "#### How it Works\n",
        "1. **Retriever** finds the top-k most relevant chunks for the query.\n",
        "2. **Prompt Template** merges those chunks with the user’s question into a single prompt.\n",
        "3. **LLM** generates an answer **only using** that context.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 New Classes / Functions\n",
        "- **`vectorstore.as_retriever()`** — Wraps FAISS into a retriever interface.\n",
        "- **`ChatPromptTemplate`** — Template for building structured prompts.\n",
        "- **`create_stuff_documents_chain()`** — Creates a chain that “stuffs” all retrieved documents into the prompt.\n",
        "- **`create_retrieval_chain()`** — Combines retriever + LLM chain into a single callable RAG pipeline.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal Runnable Example (Gemini)\n",
        "\n"
      ],
      "metadata": {
        "id": "DkWE0Po0A-KW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pre-req: You must have `vectorstore` from Lesson 9\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "# Step 1: Create retriever\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "# Step 2: Initialize Gemini chat model\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "\n",
        "# Step 3: Create prompt template\n",
        "prompt = ChatPromptTemplate.from_template(\"\"\"\n",
        "You are an assistant that answers questions based only on the provided context.\n",
        "If the answer is not in the context, say \"I don't know.\"\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{input}\n",
        "\"\"\")\n",
        "\n",
        "# Step 4: Create document chain (stuffing context into prompt)\n",
        "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
        "\n",
        "# Step 5: Create RAG chain\n",
        "rag_chain = create_retrieval_chain(retriever, doc_chain)\n",
        "\n",
        "# Step 6: Ask a question\n",
        "response = rag_chain.invoke({\"input\": \"Why do we split documents into chunks?\"})\n",
        "print(response[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dxvomkS_A-0i",
        "outputId": "6557b0d0-ffd3-407c-f0d2-30e324449fb3"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Splitting text into chunks improves retrieval quality when searching for relevant information.  It also addresses the problem that processing large documents may cause failure to process or loss of important details.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 🧪 Time to Practice — Lesson 10: RAG with Web Scrape\n",
        "\n",
        "**Goal:**  \n",
        "Scrape a single public article, chunk it, store in FAISS, and query it via RAG.\n",
        "\n",
        "---\n",
        "\n",
        "#### **Step 1 — Scrape and Load**\n",
        "```python\n",
        "!pip -qU beautifulsoup4\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://example.com/article\"  # replace with your chosen article\n",
        "loader = WebBaseLoader(url)\n",
        "web_docs = loader.load()\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "#### **Step 2 — Chunk**\n",
        "\n",
        "```python\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=120)\n",
        "chunks_web = splitter.split_documents(web_docs)\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "#### **Step 3 — Build Vector Store**\n",
        "```python\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "emb = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "vectorstore = FAISS.from_documents(chunks_web, emb)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "\n",
        "---\n",
        "#### **Step 4 — RAG Chain**\n",
        "\n",
        "```python\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Answer using only this context:\\n{context}\\n\\nQuestion: {input}\"\n",
        ")\n",
        "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, doc_chain)\n",
        "\n",
        "```\n",
        "\n",
        "---\n",
        "#### **Step 5 — Ask 2 Questions**\n",
        "```python\n",
        "for q in [\n",
        "    \"Ask something clearly in the article\",\n",
        "    \"Ask something not covered in the article\"\n",
        "]:\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(\"A:\", rag_chain.invoke({\"input\": q})[\"answer\"])\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "# Practice Code Below"
      ],
      "metadata": {
        "id": "6q7J8AJJCVx_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "\n",
        "url = \"https://en.wikipedia.org/wiki/Naruto\"  # replace with your chosen article\n",
        "loader = WebBaseLoader(url)\n",
        "web_docs = loader.load()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8h381-CsBZq4",
        "outputId": "2e6a303f-02d9-4dc0-e593-1b4de95327ca"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=120)\n",
        "chunks_web = splitter.split_documents(web_docs)"
      ],
      "metadata": {
        "id": "sraS8TuMDWdl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "\n",
        "emb = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "vectorstore = FAISS.from_documents(chunks_web, emb)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 5})"
      ],
      "metadata": {
        "id": "44Us7aytDbNf"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains import create_retrieval_chain\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.6)\n",
        "prompt = ChatPromptTemplate.from_template(\n",
        "    \"Answer using only this context:\\n{context}\\n\\nQuestion: {input}\"\n",
        ")\n",
        "doc_chain = create_stuff_documents_chain(llm, prompt)\n",
        "rag_chain = create_retrieval_chain(retriever, doc_chain)"
      ],
      "metadata": {
        "id": "C0d22R3zETJG"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for q in [\n",
        "    \"What is Naruto\",\n",
        "    \"Who is Frieza?\"\n",
        "]:\n",
        "    print(f\"\\nQ: {q}\")\n",
        "    print(\"A:\", rag_chain.invoke({\"input\": q})[\"answer\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lsddHSQwDkEA",
        "outputId": "1ead806d-99ca-4069-9633-f660bbfe0a4b"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Q: What is Naruto\n",
            "A: Naruto is one of the best-selling manga series of all time, having 250 million copies in circulation worldwide.  It's one of Viz Media's best-selling manga series, with English translations appearing on USA Today and The New York Times bestseller lists.  The seventh volume won a Quill Award in 2006.  It has been praised for its character development, storylines, and action sequences, though some felt the latter slowed the story down.  Critics noted its coming-of-age themes and cultural references to Japanese mythology and Confucianism.  The story continues in *Boruto*, where Naruto's son Boruto Uzumaki creates his own ninja path.\n",
            "\n",
            "Q: Who is Frieza?\n",
            "A: This question cannot be answered from the given context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lesson 11 — Capstone Project: RAG Agent <a name=\"lesson-11\"></a>\n",
        "\n",
        "### 🎯 Objective\n",
        "We will build a **RAG-powered Agent** that can:\n",
        "1. Search through a custom knowledge base (your ingested documents).\n",
        "2. Answer grounded questions using Gemini.\n",
        "3. Use extra tools when needed (e.g., Python calculations, web search).\n",
        "\n",
        "---\n",
        "\n",
        "### 📖 What & Why\n",
        "\n",
        "#### Why RAG + Agent?\n",
        "- **RAG** ensures answers are based on your data.\n",
        "- **Agent** adds flexibility:\n",
        "  - Can decide when to retrieve from knowledge base.\n",
        "  - Can call external tools for supplemental information.\n",
        "  - Can handle multi-step reasoning.\n",
        "\n",
        "#### Flow\n",
        "1. **Load & Chunk Docs** — From local files or scraped web pages.\n",
        "2. **Embed & Index** — Build FAISS vector store.\n",
        "3. **Retriever Tool** — Wrap retriever as a LangChain `Tool`.\n",
        "4. **LLM Agent** — Use `ZERO_SHOT_REACT_DESCRIPTION` or tool-calling agent with Gemini.\n",
        "5. **Interaction** — Ask open-ended queries; agent decides which tool to call.\n",
        "\n",
        "---\n",
        "\n",
        "### 🔑 Key Components\n",
        "\n",
        "- **`Tool` / `StructuredTool`** — To wrap the FAISS retriever as an agent-usable function.\n",
        "- **`AgentExecutor`** — Runs the agent loop with tools.\n",
        "- **`GoogleGenerativeAIEmbeddings`** — To embed chunks.\n",
        "- **`FAISS`** — Fast, local vector store.\n",
        "- **`ChatGoogleGenerativeAI`** — LLM backbone for reasoning & answering.\n",
        "\n",
        "---\n",
        "\n",
        "### 🚀 Minimal RAG Agent Example (Gemini)\n"
      ],
      "metadata": {
        "id": "VSnxDq6hFBj3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1) Imports\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.agents import Tool, AgentType, initialize_agent\n",
        "\n",
        "# 2) Load docs (example: scrape a web article)\n",
        "loader = WebBaseLoader(\"https://en.wikipedia.org/wiki/Naruto\")\n",
        "docs = loader.load()\n",
        "\n",
        "# 3) Chunk\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=700, chunk_overlap=100)\n",
        "chunks = splitter.split_documents(docs)\n",
        "\n",
        "# 4) Build embeddings + FAISS\n",
        "emb = GoogleGenerativeAIEmbeddings(model=\"models/text-embedding-004\")\n",
        "vectorstore = FAISS.from_documents(chunks, emb)\n",
        "retriever = vectorstore.as_retriever(search_kwargs={\"k\": 10})\n",
        "\n",
        "# 5) Wrap retriever as a Tool\n",
        "def retrieve_docs(query: str):\n",
        "    docs = retriever.get_relevant_documents(query)\n",
        "    return \"\\n\\n\".join([d.page_content for d in docs])\n",
        "\n",
        "retriever_tool = Tool(\n",
        "    name=\"Document Retriever\",\n",
        "    func=retrieve_docs,\n",
        "    description=\"Use this to search the knowledge base for answers.\"\n",
        ")\n",
        "\n",
        "# 6) Create LLM agent\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0)\n",
        "agent = initialize_agent(\n",
        "    tools=[retriever_tool],\n",
        "    llm=llm,\n",
        "    agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "# 7) Ask a question\n",
        "response = agent.run(\"Please summarise the story of Part 1 of Naruto?\")\n",
        "print(\"\\nFinal Answer:\\n\", response)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OZ6vsmUGDuCk",
        "outputId": "a9c9481f-eba5-449f-fd0b-db0ee51027b0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to retrieve information about the plot summary of Part 1 of Naruto.  I will use the Document Retriever to find a relevant summary.\n",
            "\n",
            "Action: Document Retriever\n",
            "Action Input: \"Summary of Naruto Part 1\"\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mPlot\n",
            "Part I\n",
            "See also: List of Naruto chapters (Part I)\n",
            "\n",
            "Retrieved from \"https://en.wikipedia.org/w/index.php?title=Naruto&oldid=1304030051\"\n",
            "\n",
            "said that the central theme in Part I of Naruto is how people accept each other, citing Naruto's development across the series as an example.[8]\n",
            "\n",
            "to prevent a coup; he accepted, on the condition that Sasuke would be spared. Devastated by this revelation, Sasuke joins the Akatsuki to destroy Konoha in revenge. As Konoha ninjas defeat several Akatsuki members, the Akatsuki figurehead leader, Nagato, kills Jiraiya and devastates Konoha, but Naruto defeats and redeems him, earning the village's respect and admiration.\n",
            "\n",
            "from Jiraiya to prepare himself for the next time he encounters Sasuke, while Sakura becomes Tsunade's apprentice.\n",
            "\n",
            "5.2\n",
            "Critical response\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5.3\n",
            "Awards and accolades\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "5.4\n",
            "Themes\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "6\n",
            "Notes\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "7\n",
            "References\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "8\n",
            "External links\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle the table of contents\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Naruto\n",
            "\n",
            "\n",
            "\n",
            "101 languages\n",
            "\n",
            "Naruto - Wikipedia\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Jump to content\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Main menu\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\t\tNavigation\n",
            "\t\n",
            "\n",
            "\n",
            "Main pageContentsCurrent eventsRandom articleAbout WikipediaContact us\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tContribute\n",
            "\t\n",
            "\n",
            "\n",
            "HelpLearn to editCommunity portalRecent changesUpload fileSpecial pages\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Search\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Appearance\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Donate\n",
            "\n",
            "Create account\n",
            "\n",
            "Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Personal tools\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Donate Create account Log in\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\t\tPages for logged out editors learn more\n",
            "\n",
            "\n",
            "\n",
            "ContributionsTalk\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Contents\n",
            "move to sidebar\n",
            "hide\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "(Top)\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1\n",
            "Plot\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "Toggle Plot subsection\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "1.1\n",
            "Part I\n",
            "\n",
            "Two and a half years later, Naruto returns from his training with Jiraiya. The Akatsuki starts kidnapping the hosts of the powerful Tailed Beasts. Team 7 and other Leaf ninja fight against them and search for their teammate Sasuke. The Akatsuki succeeds in capturing and extracting seven of the nine Tailed Beasts, killing all the hosts except Gaara, who is now the Kazekage. Meanwhile, Sasuke betrays Orochimaru and faces Itachi to take revenge. After Itachi dies in battle, Sasuke learns from the Akatsuki founder Tobi that Itachi had been ordered by Konoha's superiors to destroy his clan to prevent a coup; he accepted, on the condition that Sasuke would be spared. Devastated by this\n",
            "\n",
            "After several missions, including a major one in the Land of Waves, Kakashi allows Team 7 to take a ninja exam, enabling them to advance to a higher rank and take on more difficult missions, known as Chunin Exams. During the exams, Orochimaru, a wanted criminal, invades Konoha and kills the Third Hokage for revenge. Jiraiya, one of the three legendary ninjas, declines the title of Fifth Hokage and searches with Naruto for Tsunade whom he chooses to become Fifth Hokage instead.\n",
            "\n",
            "in Boruto, where Naruto's son Boruto Uzumaki creates his own ninja path instead of following his father's.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mThought: I now have a summary of Naruto Part 1 from the retrieved document. I will synthesize it into a concise answer.\n",
            "\n",
            "Final Answer: Naruto Part 1 follows Naruto and his team, Team 7, as they complete missions and participate in the Chunin Exams.  A major plot point involves Orochimaru's attack on Konoha, resulting in the Third Hokage's death.  The search for Tsunade to become the Fifth Hokage ensues.  Throughout the arc, Team 7 faces various challenges, and Sasuke's eventual betrayal and departure to join Orochimaru sets the stage for future conflicts.  The Akatsuki's actions in capturing tailed beasts also become a significant ongoing threat.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "Final Answer:\n",
            " Naruto Part 1 follows Naruto and his team, Team 7, as they complete missions and participate in the Chunin Exams.  A major plot point involves Orochimaru's attack on Konoha, resulting in the Third Hokage's death.  The search for Tsunade to become the Fifth Hokage ensues.  Throughout the arc, Team 7 faces various challenges, and Sasuke's eventual betrayal and departure to join Orochimaru sets the stage for future conflicts.  The Akatsuki's actions in capturing tailed beasts also become a significant ongoing threat.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KDIfavq8FfMO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}